---
title: Books: Antifragile
---

- tags: #[[ðŸ“¥inbox]] #antifragile

- author : [[Nassim Taleb]]

- Takeaway: Everything gains or loses from volatility. Fragility is what loses from volatility and uncertainty. 

- Prologue
	 - The [[antifragile]] is something the thrives and gets better in uncertainty, randomness, disorder, volatility, and stressors. It is beyond resilience or robustness. Antifragile systems also like the passage of time. 
		 - Antifragility lets us deal with the unknown, do things without understanding themâ€”and do them well. 

		 - For example, our understanding of health improves once we encounter disease. If our bodies and minds are not stressed or challenged, learning and improving won't happen as quickly. 

		 - If our intelligence is antifragile, then depriving us of challenges and opportunities for stressors is harming us. 

		 - > The process of discovery (or innovation, or technological progress) itself depends on antifragile tinkering, aggressive risk bearing rather than formal education. 

	 - Fragility is predictable but risks are not (other than in casinos) - this provides a solution to the [[Black Swan]] problem â€”the impossibility of calculating the risks of consequential rare events and predicting their occurrence.
		 - Sensitivity to harm from volatility is tractable, more so than forecasting the event that would cause the harm.

		 - We can then move situations and environments from fragile toward antifragile, through reduction of fragility or harnessing antifragility. 

	 - Complex systems don't need complicated systems and regulations and intricate policies. The simpler the better. __Less is more and usually more effective.__

	 - Categories of "things"
		 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2FzDRWBp73fM.png?alt=media&token=232b14dc-165e-4ec5-b227-b95b6f447bff)

		 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2F6qEYgGHsCS.png?alt=media&token=aa06c3f0-ed7f-47e0-9477-33d128c6b9b7)

		 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2F0oVa82e4Lm.png?alt=media&token=39793f19-f383-4781-9bbe-69c314fca6cd)

		 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2FpommVoi_Zb.png?alt=media&token=77858495-c5e7-42f3-8a01-dd4e020f0395)

		 - fragile - doesn't like uncertainty, hates mistakes, wants perfection, is hurt by unpredictability

		 - robust - doesn't care about uncertainty

		 - antifragile - like uncertainty, likes mistakes, grows from experiences, challenges and change

		 - We can move from one spectrum to the other by either adding or removing instability/predictability

	 - Antifragility is not necessarily desired, maybe robustness is the more desirable state

- Chapter 1
	 - Examples of proto-antifragility is caloric restriction to increase lifespan. Removing stressors from certain systems may in fact do harm. 

- 2. Overcompensation and overreaction everywhere
	 - Undercompensation from the absence of a stressor, degrades the best. Overcompensation makes us work harder. 
		 - > Most humans manage to squander their free time, as free time makes them dysfunctional, lazy, and unmotivatedâ€”the busier they get the more active they are at other tasks.
			 - If you need something done fast, give it to your busiest or second busiest person in the office. 

			 - Mental effort makes us work harder, it activates more vigorous and analytical brain machinery. 
				 - Our concentration is better where there is a modicum of background noise. 

	 - Redundancy is how systems manage risk. (e.g., humans have two kidneys, lungs, we have extra things)
		 - A system when overcompensating is preparing for a worse future alternative. Even if the worse outcome doesn't come to fruition the extra capacity maybe useful, such as selling at a higher price. 

	 - Secret information, rebellion, and some forms of "love" (obsession) are antifragile

	 - To discern fragility, we can look at how people dress. If they don't care what others think about them they are more likely antifragile to the opinions of others about their reputation. Those who have to dress up at work are more fragile of the information that spreads about their reputation. 
		 - When you don't have debt you don't care about your reputationâ€”and when you don't care about your reputation that you tend to have a good one. 

	 - Information can be antifragile if "smear" campaigns end up benefiting the one being smeared. They are in an antifragile situation or environment. 

- Chapter 3
	 - Acute stressors with ample recovery time are beneficial to antifragile systems, while chronic stress is harmful.

	 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2F3z7iINp8K_.png?alt=media&token=d458b68e-5c96-45b8-ba56-1932e8e6c899)

	 - We are averse to stressors and don't understand them, but we are committing crimes against life, the living, science, and wisdom, for the same of eliminating volatility and variation.
		 - Our source of mood swings, sadness, bout of anxiety, are a source of intelligence. 

		 - The treadmill though hELPful, submits to us the same flat stressor compared to the variability of hiking on natural terrain

- Chapter 4
	 - **Antifragility through layers. **The antifragility of some comes at the expense of the fragility of others. (i.e., the fragility of starts ups benefits the economy (antifragrile))
		 - A system maybe antifragile as a whole, but individual components of the system maybe fragile.
			 - The gene is antifragile at the expense of the living unit that dies in order to procreate and pass on its genes to its offspring. Humans are fragile but our genes are antifragile as long as we procreate.

			 - Evolution is antifragile from the randomness of gene mutations and environmental factors that influence which living units survive and pass on the stronger genes

			 - We can see layering in economy. For the economy to be antifragile, individual businesses have to be fragile, they have must be exposed to challenges that can break them. 
				 - However individual businesses will seek out antifragility, against the fragility of the economy as a whole. 

				 - When the government intervenes in the systems and creates bailout for certain sectors, the system is not corrupted and unfit. This is the opposite of healthy risk taking. Government intervention and policies end up hurting the weak and consolidating the established.

	 - When something is fragile it depends on things following the exact planned course, with as little deviation as possibleâ€”for deviation are more harmful the helpful. 
		 - This is why the fragile needs to be very predictive in its approach and conversely, predictive systems cause fragility. Antifragility is the opposite.

	 - Errors from others can help the overall system. Plane crashes help airplane travel that much safer.
		 - > Systems like the airplane industry is a good system because it is designed to handle small errors that are independent of each otherâ€”or, negatively correlated to each other, since mistakes lower the odds of future mistakes

	 - > Someone who makes plenty of errorsâ€”though never the same error more than onceâ€” is more reliable than someone who has never made any.

	 - We should learn and enrich ourselves of information from our mistakes. We shouldn't grow defensive, embarrassed or try to explain our mistakes, instead move on.
		 - We should be careful not to see antifragility where it does not actually exist. If we survive a stressor we may have improved or we survived and not improved, and only the weaker ones did not survive the stressor. Even though the weaker ones did not survive, their failure necessarily did not make us better or improved.

- Chapter 5
	 - When we rely on human judgement we are at the mercy of a mental bias that disfavors antifragility because human don't like making mistakes and antifragility is all about making mistakes that makes us learn. 

	 - The more variability we observe in systems, the less Black Swan-prone it is. 

	 - Antifragility is difficult to attain on a large scale as individuals become abstracted as mere numbers. The harm done to a large population becomes less personal the bigger the system is, i.e., large governments compared to the more personal municipal governments. 
		 - The problem in creating [bureaucracies]([[bureaucracy]]), we put civil servants in a position to make decisions based on abstract and theoretical matters, with the illusion that they will be making them in a rational, accountable way.

		 - Smaller and local governance allows the feedback loop from decision making more personal and places "skin in the game" for the decision maker.

	 - Planning without allowing for experimentation and small mistakes can be costly.

	 - Create awareness between truth and manufactured stability. (i.e., A turkey believes that they will live and be fed forever until they are killed for Thanksgiving dinner. All their past experiences would point to a healthy life, until the past is suddenly not true anymore.)

- Chapter 6
	 - The risk properties of the fragile and antifragile environments are different for each.

	 - In the markets, fixing prices, or, equivalently, eliminating speculatorâ€”and the moderate volatility that they bringâ€”provide an illusion of stability, with periods of calm punctuated with large jumps. Because players are unused to volatility, the slightest price variation will then be attributed to insider information, or to changes in the state of the system.
		 - When a currency never varies, a slight, very slight move makes people believe that the world is ending. Injecting some confusion stabilizes the system.

		 - Variations also act as purges. Small variations prevents bigger, more disruptive changes from happening. e.g., Small forest fires periodically cleanse the system of the most flammable material, so this does not have the opportunity to accumulate. Systematically preventing forest fires from taking place "to be safe" makes the big one much worse.
			 - Systems become weaker during long periods of steady prosperity devoid of setbacks, and hidden vulnerabilities accumulate silently under the surfaceâ€”so delaying crises is not a very good idea. The longer one goes without trauma, the worse damage when commotion occurs. 

		 - Artificially suppressed volatility leads a system to extreme fragility and also displays no visible risks, therefore we don't learn and gain information from volatility (volatility is information, without it there is no feedback loop)         
			 - There is not real stability with no volatility.                                                                                                                                                                                                                                                                                                                           

- Chapter 7 NaÃ¯ve [[Intervention]]
	 - iatrogenics - harm caused by the healer, e.g., tonsillectomies
		 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2FbgAIzR_uqk.png?alt=media&token=861d12df-59a3-4f45-ba2a-b9a556069132)

		 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2FZWLunIbgKU.png?alt=media&token=4e0ecdb4-7550-461d-8d15-a6e3def9b803)

	 - naÃ¯ve Interventionism depletes mental and resources; it is rarely available when it is needed the most.
		 - naÃ¯ve intervention is the lack of awareness and acceptance of harm done by it.

		 - We need to to avoid our blindness to the natural antifragility of systems, their ability to take care of themselves, and fight your tendency to harm and fragilize them by not giving them a chance to do so. We often over intervene with minimal benefit while under intervening when intervention is necessary. 

		 - procrastination can be a tool to combat naÃ¯ve intervention. We can let events take their course and give the activists the chance to change their mind before committing to irreversible policies. We can let systems (if antifragile) express their antifragility and take care of themselves 

		 - Time is the best test for fragility, it encompasses high doses of disorder.

	 - Imperturbability, the ability to be calm under fire, it is considered a necessary trait to be come a leader. It allows one to be unruffled to small information, self-controlled in difficult situations. It allows us to listen and react to the [[signal]] over the [[noise]]. 
		 - In science noise a generalization beyond the actual sound to describe random information is totally useless for any purpose and that you need to clean up to make sense of what you are listening to.

		 - A very toxic property of data: it is toxic in large quantities, even in moderate quantities. 
			 - The more we take a look at data and information, the more noise we are disproportionally likely to get (rather, than the valuable signal); hence the higher noise to signal ratio. 

			 - Information can be a stressor, helpful for antifragility, but too much information can overcome the limits of antifragility for helpfulness where it is harmful

		 - The best way to prevent overreaction to data is to only look at very large data, never at small ones.

	 - To prevent unnecessary interventionism is to ration your supply of information, as naturalistically as possible (i.e., don't watch the news daily). The more data you get, the less you know what's going on, and the more iatrogenics you will cause. Science doesn't mean more data.

- Chapter 8 - Prediction as a Child of Modernity
	 - Robust and antifragile systems don't have to have as accurate comprehension of the world as the fragile, and they do not need [[forecasting]]. [[Redundancy]] is a nonpredictive or less predictive action. 
		 - If we have extra resources in storage we don't need to predict with great accuracy which events will cause potential difficulties. Redundancy creates antifragility, while [[debt]] causes fragility.
			 - Debt can be resources, falling behind schedule, or unplanned work.

	 - How to deal with prediction errors:
		 - We can minimize harm rather than rely on prediction to mitigate the consequences of potential disaster events.

		 - Make our systems more robust to defects and forecast errors, or even exploit the errors for our gains

		 - Antifragility is how to move forward when stresses appear (make lemonade out of lemons) - benefit from these stressors

		 - We need to stop blaming our inability to predict or see these events from happening, instead blame ourselves for blaming systems that are fragile. 

		 - Make our system greed proof or protected from the other bad characteristics of humanity or even better,  benefit from them. 
			 - Create backup plans and protections that mitigate the effects of ill-events, prepare our system for when they do happen instead of eliminating or predicting when they do happen. 

			 - Systems that lie within the domains of social, economic, and cultural life is in the Black Swan group. The physical life is much more predictable in relation. 
				 - What is nonpredictable will remain nonpredictable no matter how much math you throw at it.

- Chapter 9  
	 - [[Curiosity]] is antifragile, it is magnified by attempts to satisfy it. 

	 - A system built on understanding probability is bound to collapse.

	 - > Nothing was more hideous in his eyes than excessive refinement (wealth), in clothes, food, lifestyle, and wealth was nonlinear. Extra wealth creates endless headaches and worries.

- Chapter 10
	 - ^^Wisdom in decision making is vastly more important, not just practically, but philosophically, than knowledge^^

	 - [[stoicism]] - continuous degrading the value of earthly positions. Stoics look down on luxury. For Seneca stoicism was antifragility from fate. 

	 - Success brings asymmetry: we now have more to lose than gain. When you become rich, the pain of losing your fortune exceeds the emotional gain of getting additional wealth, so you start living under continuous emotional threat.  

	 - To relieve you of stress, mentally plan for the worst as it already happened. The rest of the day will be easy. When we mentally adjust for the worst, we can take certain risks, since we know the calculated downside of the worst-case scenario. #[[decision making]]
		 - Intelligent life is about emotional positioning to eliminate the sting of harm, which is through mentally writing off belongings so we don't feel the pain from their losses.

- Chapter 11
	 - The first step toward fragility is decreasing our exposure to the unpredictable events, like Black Swans and to let natural antifragility to work by itself. 

	 - Consider the path dependent property of fragility: what matters is the route taken, the order of events, not just the destination. i.e, you can't be successful if you don't survive.
		 - Under path dependence, we can't separate growth from risks and recession, financial returns from risks of terminal loses and "efficiency" from danger of accident. If something is fragile, its risk of breaking anything you do to improve it or make it "efficient" is inconsequential unless you first reduce the risk of breaking. 

	 - > Nothing can be done both hastily and safelyâ€”almost nothing

	 - The barbell method is exposing yourself to extreme ends of risk, at very low boring risks (90%) and also the extreme high risks (10%). This strategy minimizes the possible harm we encounter from high risks situation while also benefiting from it's abundant reward. Don't spend time in the middle. (maximally safe and maximally speculative)
		 - The barbell method can also be applied to interventionism. We can allow ourselves for exposure to small amounts of stress/challenges to learn but keep ourselves mostly safe to high dangerous situations.

	 - [[Teleological fallacy]] - the illusion that we know exactly where we are going, that we know what we wanted in the past, and that others have succeeded in the past by knowing where they were going.  It assume completeness of vision and locks us into rigid, hard to revise programs. We think we know what we want tomorrow, today. It is also the illusion that others, too, know where they are going, and that they would tell you what they want if you just asked them. 
		 - > Never ask people what they want, or where they want to go, or where they think they should go, or, worse, what they think they will desire tomorrow. 
			 - Steve Jobs' strength was precisely distrusting market research and focus groupsâ€”those based on asking people what they wantâ€” and instead following his own imagination. His modus was that people don't know what they want until you provide them with it.   

	 - Options and optionality gives us antifragile qualities. It allows us to benefit from the positive side of uncertainty, without a corresponding serious harm from the negative side. #[[Project Management]] #[[risk managing]]

- Chapter 12
	 - Intelligence can lead us to discount antifragility and ignore the power of optionality.

	 - __sour grapes__ The story we tell ourselves about the grapes that we can't reach are sour, even though we don't really know. We call it sour so grapes we cant' reach lose their appeal by labeling them defective. We need to experience and try the options we have before telling ourselves we don't like fame or money, simply to our inability to achieve them.

	 - __[[option]]s__ don't care about the average or adverse outcomes, only the favorable ones (since the downside doesn't count beyond a certain point)
		 - An example of an option is a rent controlled apartment. You are not obligated to stay there but are protected from drastic rent increases. And if the rent does go down you can leave and rent the new lower market price elsewhere. 

		 - If you have [[optionality]], you don't need to have intelligence, knowledge, insight, skills because you don't have to be right that often. All you need is the wisdom to not do unintelligent things to hurt yourself (some acts of omission) and recognize favorable outcomes they occur. 
			 - The key is that your assessment doesn't need to be made beforehand, only after the outcome)

		 - **option = asymmetry + rationality**

		 - The fragile has no options, while the antifragile only has to choose the best option that will give the most rewards.

		 - Options benefit from variability, but also when situations which errors carry small costs. Happy errors (small) can bring gains (learning) and unhappy ones bring losses (too large)

		 - Options are in plain sight, we only need to see them. 

	 - __dispersion__ Business like luxury good don't care about the average, only about the available funds from thee wealthy

	 - [[asymmetry]] means ((004b6363-5aaa-41a7-b2e8-5592eff0793f))
		 - Good  asymmetry is when there are more upsides and benefits than harm and losses

- Chapter 13
	 - We are terrible in intentionally creating future technologies and solutions. We rely on [[randomness]] to come up with good ideas. [[Books: Where Good Ideas Come From]]
		 - Randomness plays a role at two levels: the invention and the implementation. Implementation does not necessarily follow invention. It also requires luck and circumstances.

	 - **Identifying options and their categories**
		 - __The half-invented__ Taking the half-invented to the invented is usually the breakthrough as it means fighting naysayers, administrators, empty suits, etc. Sometimes it takes vision to figure out what to do with a discovery.
			 - The simpler and more obvious the discovery, the less equipped we are to figure it out by complicated methods. The key through significant discovery of the implementation is through practice.  

			 - __translational gap__ the lag between formal discovery and first implementation
				 - few want to jeopardize their job and reputation

	 - There are two types of knowledge: 
		 - 1. not exactly "knowledge", it is the way of doing things that we cannot really express in clear and direct language, sometimes referred as apophatic (knowledge from God)

		 - 2. Knowledge acquired through school, the type of knowledge you can get graded for, can codify, anything that is explainable, rationalizable, provable, etc.

		 - There may be naÃ¯ve error in attributing and overestimating the importance of the strict definition of knowledge in human affairsâ€”and degrading the uncodifiable, more complex, intuitive, or experienced based type of knowledge
			 - Random tinkering (antifragile) -> Heuristics (technology) -> Practice and apprenticeship vs practice -> academic theories -> academic theories

	 - [[Epiphenomena]] - the illusion that a secondary effect or byproduct that arises from but does not causally influence a process. (e.g., Observing boys mostly have short hair and incorrectly concluding that a short hair cut determines gender)
		 - Consider epiphenomena when people give you their reasoning or justification of their beliefs and reasoning #reasoning #[[Critical Thinking]]

		 - We are easily fooled by the sophisticated. We hardly self-correct our thoughts on science, medicine, and mathematics even though they may be sharing wrong information.

- Chapter 14
	 - University knowledge does not necessarily mean smarter students. This is a myth. Switzerland is a place with a low level of formal education and relying on apprenticeships. But often society will think that prestigious universities create better students. 
		 - Knowledge, one that is sophisticated is born of need and success from our difficult experiences. 

	 - > Doer's, like entrepreneurs are often selected to execute, not necessarily be thinkers, and it would unfair, wrong, and insulting to measure them in the talk department. The same with artisans, the quality lies in their product, not their conversations. 

	 - [[Optionality]] is a tool to handle uncertainty, to work rationally without understanding the future. [Narratives]([[narrative]]) is the opposite. It is controlled by uncertainty, by having it create "false"  narratives to explain it (uncertainty)

	 - > In [[theory]] there is no difference between doing and thinking; in practice there is. - Yogi Berra

	 - Expert problems (in which the expert knows a lot but less than he thinks he does) often bring fragilities, and acceptance of ignorance the reverse. 

	 - We often wrongly assume the story and narrative we tell ourselves for causes and explanation of events, for another less visible from the outside, less tractable, less narratable. We make convenient stories to provide explanations to events that may not be true. 

	 - When you are [[fragile]] you need to know a lot more than when you are antifragile. Conversely, when you think you know more than you do, you are fragile (to error)

	 - Innovation and growth are largely fueled by antifragile risk-taking and not formal and organized research. It's not that theories and research play no role, it is that we are fooled by randomness, so we are fooled into overestimating the role of good-sounding ideas. 

- Chapter 15 
	 - We often misconstrue PhDs and higher education to practical intelligence and experiential intelligence within certain fields. Academic intellect doesn't necessarily translate to practical knowledge or expertise. Someone may have studied a specific career field, does not mean that they can practice.
		 - Often we get the incorrect picture of a knowledge field because the writers are intellectuals rather than hearing first hand from the doers. The doers don't necessarily write about what they do, they execute. 

		 - We shouldn't put theory into practice, but create theories from practice. 

		 - Experimentation can make people much more careful than theories.  Cooking is an example domain, where practice leads to theories (recipes), rather than the other way around. Physics is a counter-example to this as discoveries were discovered using theory. (e.g., discovery Neptune by Leverrier's derivation of existing planets, Higgs Boson, and Einstein's theory of relativity)

		 - Antifragility would recommend investment-style investing as you would want to limit your overall risk by spreading it to all the stock market rather than banking on a single stock. 

		 - "Knowledge" in complex domains inhibits research (i.e., studying the chemical composition of ingredients will make you neither a better cook nor a more expert tasterâ€”it might even make your worse at both)
			 - > Corporations are in love with the idea of the strategic plan. They need to pay to figure out where they are going. Yet there is no evidence that strategic planning works we even seem to have evidence against it...It makes the company corporation option-blind, as it gets locked into a non-opportunistic course of action.
				 - What is the option to strategic planning then? I'm sure plans are good but up to a point that volatility and planning can co-exist? 

- Chapter 16
	 - teleology
		 - the explanation of phenomena in terms of the purpose they serve rather than of the cause by which they arise.
			 - "no theory of history can do without teleology"

	 - The skills and knowledge we learn in the classroom or any domain does not necessarily they transfer to another environment. (i.e., schooling may not properly train us to be good workers out in the field)

	 - Don't be impressed by other's people's degrees. Be impressed by the knowledge they have through "doing"

- Chapter 17
	 - A severe mistake we can make in life is to mistake the unintelligible for the unintelligent. In a way it resembles mistaking what we don't see for the nonexistent, also similar to mistaking absence of evidence for evidence of absence.

	 - Never let anyone else frame the question to you unless you agree with it. Never respond with a straight answer to a question to a question that makes no sense to you. 

	 - > Perhapsâ€”thus he [Socrates] should have asked himselfâ€”what is not intelligible to me is not necessarily unintelligent? There is a realm of wisdom from which the logician is exiled?

	 - When we make decisions it isn't based on true or false, but rather the consequences of truth and falseness. We should pay attention to the questions that have the biggest payoff rather than wasting time and resources on asking insignificant questions.
		 - (e.g., even though most people are not terrorists we have gate screenings at the airport because the consequences of letting a terrorist into the plane is asymmetrically destructive)

		 - Instead of leadership pouring attention to individual projects or a specific person who is a low rung like project managers, attention should be paid to the systems and systems owner who have far more influence and impacts on their decision making.

- Chapter 18
	 - Fragile systems are those where the cumulative effect of small shocks is smaller than the single effect of an equivalent single large shock.

	 - For antifragile systems, shocks bring more benefits (equivalently, less harm) as their intensity increases (to a point)

	 - (get image of figure 13)
		 - [[Nonlinear system]]s either benefit or are harmed more by the event size, as opposed to linear systems. For example, as you add more cars on the road the effect on traffic becomes increasingly nonlinear, meaning that the effect of each additional car is greater than the previous addition. #nonlinear

	 - Size hurts you at times of stress; it is not a good idea to large during difficult times, no matter what business schools say about "economies of scale".

	 - It is completely wrong to use the calculus of benefits without including the probability of failure. 

	 - Bottlenecks are the mothers of all [[squeeze]]s. Example hundreds of people trying to exit the same time. 
		 - A squeeze occurs when people have no choice but to do something, and do it right away, regardless of costs.

- Chapter 19

- Via Negativa - Subtractive Knowledge
	 - The barbell method for antifragility is through removing fragility
		 - Example. To get rich avoid being poor. To make smart decisions, avoid stupidity.
			 - **How to detect fragility** #nonlinear #Non-linear
				 - Fragility is directly from nonlinearity/acceleration and convexity effects, and convexity is measurable. 
					 - We can detect acceleration (nonlinearity) of harm and applies to anything that entails decision-making under uncertainty and risk management. 

					 - To minimize the effect of "mistakes" make small but frequent decisions rather than a large ones. Small mistakes are less costly in totality than a large mistake

					 - Don't trust models as if one wrong assumption and model, you may be incurring a substantial risk. 
						 - Models about averages can be deceptive. For example, if you were told you would be spending two hours at an average of 70 degrees you would think that would be great, but if you spent the first hour at 0 degrees then the second at 140, then the model would not sound great anymore. Clearly, temperature changes become more and more harmful as they deviate away from seventy degrees.

				 - If you have favorable asymmetries or positive convexity, options being a special case then in the long run you will do reasonably well, outperforming the average in the presence of uncertainty. The more uncertainty, the more role for optionality to kick in, and the more you will outperform.

	 - The greatest contribution to knowledge consists in removing what we think is wrong. We know a lot more what is wrong than what is right. So knowledge grows by subtraction much more than by addition. This is because what we know today might turn out to be wrong but what we know to be wrong cannot turn out to be right, at least easily. 
		 - Since a small observation can disprove a statement, while millions can hardly confirm it, disconfirmation is more rigorous than confirmation.  

	 - __Less is more__
		 - Simpler methods for forecasting and inference can work much more effectively than complicated ones. The simple rule of thumbs are not perfect but are designed for intellectual humility and abandoning the aim at sophistication to yield powerful effects.
			 - Protect yourself from the rare negative black swans instead of concentrating on the the small volatility in life. Or exploit the positive black swans rather than exerting effort and energy on the small opportunities in life. 

- Chapter 20
	 - When forecasting and predicting the future we tend to overtechnologize instead of removing. We need to respect the past more, curiosity of the historical records, a hunger for the wisdom of the elders. Pay attention to the things that are around and to the things that have survived. 
		 - Example: we still cook with pots and pans even though those utensils have existed for hundreds of years. 

		 - The concept of perishable and non-perishable things would aid in forecasting. A non-perishable item is a book like the bible, the more time it is in print the more we can assume it will continue to stay in print. However, something like a human being, the more it stays alive we can conjecture that its lifespan becomes more limited. Another example is the Pyramid vs the Berlin wall (the Berlin wall fell)

	 - Information has a property to hide failures, often society will highlight the few successes within a given field but ignore the possibly more numerous failures of the same domain. The way we present information can also lessen or increase its impact. For example if we announce that we lost $10k compared to saying that our investment is now 785k instead of 795k, then we will see the former as more harmful.
		 - This is because our brains have a predilection for shortcuts

	 - The treadmill effect is always buying the newest thing of something, always upgrading our things. We tend to notice the small differences between items as opposed to seeing their commonality. Even though a year ago we were excited by our phone model, a year or two later, we want to upgrade and see the current phone as inferior, even though two years ago we were excited by it.
		 - When we upgrade we get a boost of satisfaction with the changes in technology, but we then get used to it and start hunting for the new thing.

	 - Even though we don't understand concepts like religion, if you're an atheist, if that something has survived for hundreds of years it is likely to outlive its detractors.

- Chapter 21 
	 - The non-natural needs to prove its benefits, not the naturalâ€”according to the statistics dealing with nature, nature is to be considered much less of sucker than humans. In a complex domain, only timeâ€”a long timeâ€”is evidence.
		 - The "do you have evidence" questioning is a fallacy. The harm of this line of questioning is too great, it is similar to the one misinterpreting the no evidence of disease for evidence of no disease.

	 - The good is mostly in the absence of bad. 

- Chapter 22
	 - Wealth may lead to fragility to certain people as poverty may be a factor of antifragility for others. Poverty can simplify and bring great in the form of healthy stressors if done right. Wealth can bring too much comfort and degrade our health in the abundant lifestyle. 

- Chapter 23
	 - The robustness of society is due to the people who sacrificed themselves for the greater good of everyone else.

	 - Certain job roles and industry manipulate fragility and antifragility by transferring risk  and rewards at the expense of others. Many people make decisions at the expense of others. The outcomes of their decisions don't effect them. 
		 - Every opinion maker needs to have "skin in the game" in the event of harm caused by reliance on his information or opinion. 

		 - We need to build redundancy, a margin of safety, avoiding optimization, mitigating (even removing) asymmetries in our sensitivity to risk.

	 - We can detect the bullshit of others through their actions and what they invest in (time, money, emotions, etc.) We can see the credibility of research if the researchers apply their findings to their own personal life. __Do these people have skin in the game?__
		 - Bankers are an example where they have no skin in the game. They still get millions in bonuses even though they collapsed the economy

- Chapter 24 - Fitting ethics to a profession
	 - Wealth doesn't necessarily mean you are more independent. There's a phenomenon called the treadmill effect where you need to make more in order to stay in the same place.

	 - One should give more weight to witnesses and opinions when they present the opposite of a conflict of interest. 

	 - More data means more information, but it also means more false information. Big data can only truly deliver via subtractive style knowledge, it can effectively used to debunk, not confirm. 

	 - Collective knowledge
		 - Because everyone is doing or that's how others do it abound as a counter-example for group knowledge. This is not the same thing as group learning. Group knowledge is like peer pressure, influencing an individual into taking an action, left on their own, would have not done so.

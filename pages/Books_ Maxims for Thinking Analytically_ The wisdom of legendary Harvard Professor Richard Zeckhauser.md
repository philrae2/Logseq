---
title: Books: Maxims for Thinking Analytically: The wisdom of legendary Harvard Professor Richard Zeckhauser
---

- **tags:** #[[Critical Thinking]]  #[[Decision Making]]
- **author:** [[Dan Levy]]
- **status:** #[[üì•inbox]]
- **link:** [Amazon.com: Maxims for Thinking Analytically: The wisdom of legendary Harvard Professor Richard Zeckhauser eBook : Levy, Dan: Kindle Store](https://www.amazon.com/Maxims-Thinking-Analytically-legendary-Zeckhauser-ebook/dp/B098GLJS51/ref=sr_1_1?crid=123DOIPIWX4DB&dchild=1&keywords=maxims+for+thinking+analytically&qid=1631835951&sprefix=maxims+for+thi%2Caps%2C174&sr=8-1)
- #[[Literature Notes]]
	- [[Finding an extreme scenario of a problem may offer insights to help you solve it]]
	- [[To help clarify thought, problem, or situation, formulate the simplest task that's easy enough for anyone to solve or understand]]
	- [[Don't take refuge in complexity when problem-solving, seek simplification]]
	- [[Complex models or explanations are a failure if people don't understand them and especially if they cause harmful actions]]
	- [[Simplify complex situations with a more understandable everyday analogue]]
	- [[Carefully think through statistics and uncertainty, options that are uncertainty may provide more interesting and potentially high impact solutions]]
	- [[Be humble in your thinking so we don't overlook the weakest links in our decision making]]
	- [[Know the difference between risk, uncertainty, and ignorance when trying to understand or solve a problem]]
	- [[In uncertain situations make sure you understand the levels of risk and that you aren't in an ignorant position to properly plan and mitigate outcomes]]
- #[[Reference Notes]]
	- Maxim 1 - When you are having trouble getting your thinking straight, go to an extreme case
		- Going to an extreme case can sometimes help you discover the key insight of a problem or situation you are trying to understand. 
		  id:: 103e4354-69cd-4e33-b8b6-5d2348d85cdd
			- Xiaochen Fu is one of Richard‚Äôs former students at the Kennedy School and now a manager at the Bank of China. When she worked at Agricultural Bank of China, the third largest bank worldwide, she used this maxim to help the bank make its transition to the digital era. At a time when clients were increasingly using smartphones to conduct banking transactions, her bank still had more than 300,000 staff working at 25,000 branches around the country. Some branches found that fewer and fewer clients came in person. She and her staff were struggling to decide how they should adjust the number and location of their branches. ‚ÄúThen I remembered Professor Zeckhauser‚Äôs maxim.
			- **To find the extreme case, we went through regulations and procedures for all the services provided by a full-function bank branch, in order to identify which services would be very difficult or impossible to deliver online.** 
			  id:: aa9e3aa4-0472-4b8b-854c-42b051064afb
				- (For example, the government forbids third-party couriers to deliver physical gold, so clients who want to buy physical gold products must go to branches.) After finding all such services, and considering the needs and preferences of clients served at different branches (for example, senior clients and rural area clients still prefer face-to-face financial services), it became much clearer which branches should be closed, and which ones should be saved. The planning project proved to be cost-efficient, and allowed the bank to adapt to the digital age and better meet the needs of our clients. I reckon that the maxim gave me not only the tools but also the courage to deal with such complicated conditions.‚Äù
			- Xiaochen‚Äôs account identifies two critical benefits a maxim may bring. It can help you focus on how to approach a problem, and it can give you the courage to take action when you determine the best decision. This is true for many other maxims in this book.
	- Maxim 2 - When you are having trouble getting your thinking straight, go to a simple case
		- ^^Try to gain the skill to see and distill, simple principles, when others only see murky complexities.^^
		- We can combine the maxim of going to the extremes with finding the optimal solution when problem solving. 
		  id:: 8d82022e-0986-412a-b7ad-a49f48569ab3
			- ‚ÄúI advocate Richard‚Äôs maxims on clarifying thought by going to simple and extreme cases. I don‚Äôt think of the two as distinct.** To design an algorithm that demonstrates a sophisticated skill, it is helpful to formulate a task that‚Äôs simple enough for a human to easily solve while pushing to the extreme the level of skill required of a general algorithmic solution not specialized to the task.** Not everyone thinks this way; some find it strange to work on such simple problems when the field is already able to address such complex ones. But I‚Äôve found this to be a fruitful way to develop ideas that can then be ported to complex domains. With these maxims in mind, my teaching tends to focus on such simple and extreme cases."
			- Example:
			  id:: ede6b663-02d6-47f0-aefb-ee7f41380573
				- John Horton, a faculty member at the MIT Sloan School of Management and a former student and coauthor of Richard‚Äôs, used this simplicity maxim to tackle a question he was trying to understand in the ride-sharing market (Uber, Lyft, etc.): From a societal perspective, should drivers know where a passenger is going when they decide whether to take a trip? On the one hand, knowing that information allows drivers to accept the ‚Äúgood‚Äù trips and not the ‚Äúbad‚Äù ones. If many drivers do this, the wait-time for ‚Äúbad‚Äù trips could be very long or, even worse, passengers needing ‚Äúbad‚Äù trips might never get picked up. On the other hand, if drivers differ in their costs (for example, it is cheaper to pick up a passenger going your way as your day is ending), letting them pick and choose among trips can be economically efficient; the trip will go to a driver for whom the trip is more beneficial. Creating a model that fully captures all such relevant parameters can get very complicated very fast.
				- John simplified the problem by assuming that there are just two kinds of trips, ‚Äúgood‚Äù and ‚Äúbad,‚Äù and the two types are equally likely. He also assumed that drivers only have two possible strategies: 1) accept all trips, or 2) accept ‚Äúgood‚Äù trips and reject ‚Äúbad‚Äù ones. By simplifying the problem (two kind of trips, two strategies only), he gained insights he would not be able to get otherwise.
				- In this case, solving the model yields the insight that the ratio of good trips (which he calls ‚Äúpeaches‚Äù) to bad trips (which he calls ‚Äúlemons‚Äù) is the fraction of drivers who accept all rides. At this stage, he also applied the going-to-extreme maxim from earlier in this chapter: ‚ÄúAs I think more about this, it makes sense: if everyone is picky, the ratio of peaches to lemons = 0, which means it‚Äôs all lemons (because they always get kicked back to the pool of riders). If peaches/lemons = 1, the trips are equally likely, which makes sense, because no lemons get kicked back when no one is picky. Note that here, I‚Äôm going to the extreme cases of all picky or no picky drivers.‚Äù
				  id:: cab54873-3752-4a08-850f-1412bd9c6b1c
	- Maxim 3 - Don't take refuge in complexity
		- **We get lost in the complexity of a problem to avoid the hard thinking needed to get to its core. **
		  id:: 6e650e76-a2f7-4b02-bf73-06304436c29b
		- While a model can yield a result that might not have been obvious, an analyst‚Äôs job is not complete until he or she can decipher the intuition behind the unexpected result ‚Äì and be able to explain it to decision and policymakers in plain language (maybe with the help of a diagram or two). **Models whose results remain a mystery are not useful; models that can be translated into intuitive insights and be broadly understood can be useful.**‚Äù
		  id:: 6f41acab-40ef-4c1b-a590-5be06cdf6cb0
		- For I often find myself taking refuge in complexity, when trying to model an economic phenomenon. **Invariably, it turns out that when doing, so I am really hiding from my failure to identify the critical question at hand.** 
		  id:: 1088a968-55f1-4053-9d4a-0186ccf41587
		- **By seeking comfort in complexity, I find myself moving too quickly from analysis to meta-analysis. I end up looking for generality without knowing what are the insights which can most usefully be generalized**. This, in a word, is obscurantism and ‚Äì in no small part due to Richard‚Äôs influence ‚Äì I am dead set against it!‚Äù
		  id:: 69225a87-4ef9-4e94-b69b-20e0f1706175
		- In my own work for Professor Zeckhauser,** my first reaction to a difficult problem is often to think about how I might apply a complicated technique to it, instead of really understanding the basic problem at hand**.
		  id:: 34e8acaa-9b5d-46c5-9e07-ab4dd67c88d4
		- **Sometimes we take refuge in complexity to avoid the analytical work that might be helpful to solve a challenging problem**. But as W. Kip Viscusi suggests, this is a grave mistake.
		- He recalls using this maxim in the context of analyses where some components cannot be precisely estimated. ‚ÄúRather than do a reasoned analysis, some people would rather pronounce the problem as being too complex and not amenable to analytic tools. I have found that this maxim is pertinent to almost every risk and environmental regulation issue. The coronavirus crisis of 2020 is the most recent example of where the maxim comes into play. Some have suggested that the estimates of the illness risks and the likely economic consequences are too uncertain to even think about doing an analysis. But this is exactly the kind of situation in which thinking analytically is likely to yield the greatest dividends.‚Äù
		- **This embrace of simplicity can also be useful in moving projects forward.**
			- If I‚Äôm planning a meeting, start anywhere ‚Äì start simply ‚Äì and build. If I‚Äôm planning a project, strip it down to the bare essentials ‚Äì the simplest case ‚Äì and flesh out the details as you go.‚Äù
		- The simplicity maxim is important when asking questions to understand the work of others.
			- ‚ÄúFiguring out a simple way to ask something helps get your own thinking clear. Just do the calculation of the potential benefits and costs of asking a simple question, which might be perceived as a stupid question. The downside risk of asking the stupid question is that listeners unfavorably update their prior impressions, and you experience a moment of embarrassment. Both downsides are remediable and pass quickly even on the occasions when you don‚Äôt successfully remediate them. The upside benefit is that you actively clarify your own understanding in a way you can‚Äôt always achieve without the effort to put it into words. Moreover, you clarify the issue for bystanders; you might help yourself and others gain a new insight; and you gain the gratitude of those others who were also confused. Particularly once you consider the habitual biases against taking little risks, the balance almost always favors asking the question. You also gain a little admiration from others for your courage, but that‚Äôs an undeserved bonus: they only think it took courage because they didn‚Äôt think through this calculation.‚Äù
			- Why is the simplicity maxim easy to understand, but hard to do? For one thing, the issues we work on are often complex‚Äîhow to deliver affordable high-quality health care, preserve national security in a world with nefarious non-state actors, or manage a globalized economy. Such issues are not easy to simplify concisely. Furthermore, we were actually taught to violate the KISS principle in school. When we were asked in a history exam ‚Äòwhy did the Roman Empire fall?‚Äô typically we wrote furiously away, filling as many blue books as possible. We then let the instructor search for the three or four key points buried in our brain dump. Maybe we were awarded an A in school for that, but we won‚Äôt get an A in the real world with that approach. We cannot take refuge in complexity and bulk. Our audiences will not edit our thinking and communications for us. We must edit, that is, simplify them ourselves.‚Äù
	- Maxim 4 - WHEN TRYING TO UNDERSTAND A COMPLEX REAL-WORLD SITUATION, THINK OF AN EVERYDAY ANALOGUE
		- An example of using a more approachable and understandable as a mental stand-in for complex real-world situations are negotiations with your family or a plumber than extrapolating it to negotiations that take place between two countries like the Iran nuclear deal.
		  id:: 735acd5c-9d29-48ec-883d-46022dac4b4c
		- The Niagara bucket model:
			- For example, imagine you are contemplating transporting 100 identical items, one by one, over the Niagara Falls using buckets. There are two types of buckets. The first type has been used 100 times and succeeded in 70 of them. The second type has been used 2 times and succeeded only once. What would you do? This is the kind of classic puzzle that Richard gives to his students and colleagues. Pause for a minute to think about it before you read the answer in the next paragraph.
			  id:: 8dd2cbac-226b-44b1-9356-9f807da8a97f
			- In the absence of any other information or constraints, you should use the second bucket for a few times until you have a better sense of its overall success rate. With the first one, you are reasonably sure that its success rate is close to 70 percent, whereas with the second one you are highly uncertain because it has only been used twice. So you should use the second bucket a number of additional times until you accumulate more evidence and either conclude that the success rate is below 70 percent (in which case you switch to the first bucket), or conclude that the success rate is above 70 percent (in which case you should continue using it).
			  id:: c5b1eb48-2661-4fdc-9729-ecb4c39b5697
			- ‚ÄúThe Niagara Falls analogy also has very important implications from the perspective of a project manager, a researcher, or anybody managing any sort of portfolio. **When making decisions, such as whether to invest time and effort in a project, think of its option value**. 
			  id:: d89e6433-feec-4b6a-b321-98dc5fc31516
			- **Projects with more uncertain outcomes are likely to be more interesting, and potentially high impact. Being the first person to explore an area (be it a research topic or a business idea), is potentially much more interesting, but also easier than entering widely explored areas. Higher-uncertainty projects can bring much higher gains.‚Äù The sooner we stop or outright reject a possible solution with high uncertainty, the less likely we will reap its benefits.**
			  id:: 47540294-3518-4d63-a5c7-28e5da80a9fe
			- To evaluate one solution to another is to find the counterfactual group that is most similar to the demographics of those who took the solution and compare to those who did not.
		- **We should never become so enamored with the strong points in our thinking that we overlook the weakest links in the chain. Furthermore, acknowledging the weakest links is often persuasive when we communicate with others. Concessions convey honesty and objectivity and make what we say more credible.**
		  id:: a546e8eb-6c5c-415d-9c4c-5e60bd4a59ee
		- Using an analogue model can also help us better understand the context and the real, more complex situation 
		  id:: 800dd55e-4125-413c-90d1-897673ab6964
	- Maxim 5 - THE WORLD IS MUCH MORE UNCERTAIN THAN YOU THINK
		- **Recognizing that the world is an uncertain place can improve planning. However, just because we do not know what type of high severity event will happen, does not mean that we should not prepare our personal lives, businesses, and investment portfolios to withstand these types of dramatic events. **
		  id:: 049cdfd1-6947-4c0f-b977-02669454c5d4
		- **Human psychology leads most of us to extrapolate the near past too far into the future. It lulls us into assurance after periods of calm.** However, if we live based on this maxim ‚Äì that the world is much more uncertain than you think ‚Äì we will be alert to potential risks and conservatively positioned when these severe events inevitably happen.‚Äù
		  id:: 190011af-98af-49ed-92f7-d8e7b82cbe9f
		- Carolyn Kousky, a former student of Richard‚Äôs and now executive director of the Wharton Risk Center at the University of Pennsylvania, studies risk management for disasters ranging from hurricanes to wildfires to terrorist attacks. She illustrates the benefits of taking this maxim into account in her work: **‚ÄúPost-disaster, there is a strong push to enact new policies that (had they been in place) would have mitigated the specifics of what was just experienced. But the next disaster is never a perfect replica of the previous disaster. We have to keep our field of vision wider, to understand our full range of futures, and prepare policies that will be robust and effective across the spectrum of possible surprises.‚Äù Many people would argue that post 9/11, the U.S. government‚Äôs response was overly focused on preventing another attack involving airplanes and not enough attention was paid to preventing other types of terrorist attacks.**
		  id:: 46dc3b57-d326-449d-a9c3-70d183edcf3a
		- **It is helpful to distinguish between risk, uncertainty and ignorance (see table below). We face risk in situations with known probabilities and known states of the world. **
		  id:: 34546445-fd47-4f6c-8c98-ed745cd180a7
		- ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2FsJsen9xtgu.png?alt=media&token=837ff542-5136-4cb3-9979-ed887dc130be) 
		  id:: b2f8adc7-b458-4baf-adee-92ef885300e8
			- For example, if you play roulette in a casino, the states of the world (represented by all the possible slots the ball can land on) are known, and the probability associated with each state (the likelihood that the ball will land in any specific slot) is also known. As Richard has written ‚ÄúCasinos, which rely on dice, cards and mechanical devices, and insurance companies, blessed with vast stockpiles of data, have good reason to think about risk. But most of us have to worry about risk only if we are foolish enough to dally at those casinos or to buy lottery cards to a significant extent.‚Äù
			  id:: 5b1db1b9-6b15-45c1-8c48-73df18c59837
			- ^^When the possible states of the world are known, but the probabilities that those states occur are unknown, we face uncertainty. Uncertainty is a much more common occurrence for most of us than risk.^^ For example, when you are trying to decide which medical treatment to undertake, you might have a good sense of the possible states of the world (cured vs. not cured) for each of the treatments you are considering, but you will not know for sure the probabilities associated with each of these outcomes and will have to make educated guesses about them. In Richard‚Äôs words: ‚ÄúUncertainty, not risk, is the difficulty regularly before us.‚Äù
			  id:: 5ee50034-c5f6-4349-8118-00e5ece948af
			- Richard has also written extensively about ignorance, a situation that goes beyond both risk and uncertainty. ^^In situations with unknown probabilities and unknown states of the world, we are simply ignorant.^^ This is the most extreme form of uncertainty. Many of the examples described earlier in this chapter relate to events that we could conceive of before they occurred, even if we thought it exceedingly unlikely that they would occur. Yet, a number of the most consequential events in our lifetimes were not imagined before they happened. The attack on 9/11 was a prime example of ignorance. Planes, which had not been considered as a possible weapon, brought down the World Trade Center, an outcome also generally considered impossible. Richard says, ‚ÄúIgnorance is an important phenomenon, I would argue, ranking alongside uncertainty, and way above risk. Ignorance achieves its importance, not only by being widespread, but also by involving outcomes of great consequence.‚Äù
			  id:: 99df84a3-7434-41ea-92c1-d8f10c79b1e5
	- Maxim 6 - THINK PROBABILISTICALLY ABOUT THE WORLD
		- The Trump vs Hillary Election probability
			- Underlying all of this was a fundamental failure either to understand or be willing to grapple with what that 29 percent chance actually means. Mathematically, it means that if you were to repeat the ‚Äúexperiment‚Äù of running the election 100 times, you should expect Trump to win 29 times. Of course, the election only happens once, so this idea is a bit abstract. In the case of election forecasting, Nate Silver and his team run thousands of simulations where the election is played out on their computers many times. For each of these simulations, a different result emerges based on the probabilities that each candidate will win a given state and other statistical assumptions. For example, in simulation #1, Trump wins 34 states including the critical swing states Michigan and Wisconsin, whereas in simulation #2, Trump wins 31 states, but this time neither Michigan nor Wisconsin goes to Trump. And so on. For each simulation, a winner is determined based on the states each candidate won and the Electoral College votes each state carries. On the night before the election, after running 10,000 simulations, the FiveThirtyEight team observed that Trump won in roughly 2,900 of these simulations, which is where the 29 percent number came from. As my former colleague Lant Pritchett said at the time, ‚Äúif there is a 29 percent chance of rain, I would bring an umbrella!‚Äù
			- Note that the correct interpretation of this 29 percent chance of winning the election is different from saying that the polls indicated that 29 percent of people were planning to vote for Trump. While the polls involve a considerable degree of uncertainty, if only 29 percent of sampled voters said they would vote for Trump, he would have had a minuscule chance of winning the election, far less than one tenth of one percent. Even if the polls were extremely inaccurate, say underestimating Trump‚Äôs chances by 10 percent, Trump‚Äôs chances would have been effectively close to zero.
			- **The 29 percent probability is an example of a subjective probability. This means it is based on judgment and cannot be calculated in the same objective way we can calculate the likelihood of drawing an ace, king, queen or jack, but not the ace of spades, if you pull a card at random from a deck.[31] Subjective probabilities are the only tool available when assessing a very wide range of real-world events (for example, there is a 60 percent chance that the price of a barrel of oil will be above $50 on June 30 of next year). They also apply to personal matters, to beliefs, and to one-time-only events. As an example, you may think that there is a 30% chance you will be promoted in your job next year. Deciding effectively in most important uncertain situations requires an assessment that uses subjective probabilities.[32]**
			- Thinking probabilistically about the world involves three distinct elements:
				- ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2F4lorbOudj4.png?alt=media&token=ef1ae07a-83c0-4a21-9694-ef89c3ce196f)
				- 1. Understanding what these subjective probabilities actually mean (as we saw above),
				- 2. Assigning probabilities to many things (events, beliefs, etc.) in our lives, to help us better understand the world around us and make better decisions, and
					- Notice that estimating subjective probabilities does not mean that your intuition or gut need to be ignored. In fact, they can help you form a fundamentally richer view of the world that recognizes the uncertainty around you.
					- Thinking probabilistically often involves comparing probabilities of two different events to determine the best path forward.
				- 3. Updating these probabilities appropriately when relevant new information comes in.
					- The third key element of probabilistic thinking is the willingness to update your probabilities, and doing so appropriately in response to new information. The process used to update our probability assessments with new information, sometimes referred to as Bayesian updating, is incredibly useful in many walks of life.
					- Bayesian Updating
						- ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2FSbv3fXDV8Y.png?alt=media&token=34fd2261-1719-451f-87eb-339a4e0f7c87)
						- Imagine that tonight your favorite professional basketball team will play against their arch-rivals. Based on their respective records thus far this season and some sports websites you consulted, you initially assess that the probability that your team wins tonight is 40 percent. Decision theorists call this a ‚Äúprior‚Äù probability or simply a ‚Äúprior.‚Äù Two hours before the game you learn that the opposing team‚Äôs superstar got injured in a freak accident that day and won‚Äôt be able to play tonight.
						- Since the opposing team wins much more often when he plays than when he does not, you update your initial probability to 55 percent. Decision theorists call this a ‚Äúposterior‚Äù probability. It will be your prior probability if you update again in response to additional new information.
						- The game begins, and your team racks up a 6-point lead at the end of the first half. Maybe now you would update your subjective probability of a victory to 65 percent. Maybe the other team now scores several times and your subjective probability drops back to 55 percent. As the game progresses, your assessments change depending on what‚Äôs happening (or more generally, on information you gather). If there are only thirty seconds left, your victory assessment might soar to 80 percent, even if your team is only up by two points and the other team has the ball. If you think this is overly academic, you can check websites such as espn.com, which do exactly this ‚Äì they report the odds of each team winning as the game evolves).
					- Sometimes, asking others to give you their assessment of a particular probability can be helpful in refining your own assessment, or to gain useful information about someone else‚Äôs views. Suppose you want to know how your friend or daughter is feeling about getting admitted into the college of her dreams. If you ask ‚ÄúDo you think you will get in?‚Äù you will receive a yes or no answer (or maybe ‚ÄúI don‚Äôt know‚Äù). But if instead you ask, ‚ÄúWhat do you think are the chances you will get admitted?‚Äù you may gain more information and will be able to have a richer conversation.
					- In the professional world, assessing the probabilities that different courses of action will lead to success, and being willing to update these probabilities, is essential to effective decision-making. It can help you choose investments, select collaborators, determine which projects to pursue, etc. It can also help you decide which projects to abandon.
						- It‚Äôs critical to know when to kill projects. Time and energy are scarce resources, and even if a project of any nature ‚Äì not just economics papers ‚Äì starts out strong, we should constantly be thinking probabilistically and updating our expected values. This is a hard but essential skill.
						- It is important it is to identify sources of high-quality signals (i.e., information about the likelihood that a project will succeed). For Steve Levitt to update his assessments and kill his projects, he had to know where to go to acquire those signals in the first place. This, too, is an essential skill. Richard has been that expert source for many of us across a range of important subjects in our lives (research topics, career choices, Thai restaurants in Cambridge, etc.).
					- Most of the time, a decision maker must decide both what information to gather, often at some cost, and when to act rather than wait to gather more information. Consider a student who has been admitted to several colleges. She might decide to call three graduates from her high school now attending the colleges she is seriously considering, or she could visit each college in person. The importance of a decision should affect her expenditures on information gathering. She will spend four years of her life at her chosen college. A trip would provide much better information than three phone calls.[40] Contrast this with her decision of where to do a summer internship. In this case, the decision might be less consequential, and hence she might decide not to travel to each of the potential locations.
					- Thinking probabilistically can be hard. As Howard Kunreuther, emeritus professor and codirector of Wharton Risk Management and Decision Processes Center at the Wharton School, University of Pennsylvania, puts it: ‚ÄúI now believe that even if people understand probability theory, it is challenging to learn how to apply these concepts when making decisions, particularly when dealing with extreme events, such as natural disasters, few people think probabilistically when deciding whether to protect themselves against future losses.‚Äù
					- Ultimately, thinking probabilistically starts by correctly viewing the world as a highly uncertain place. With that view in mind, the logical prescription is to assign probabilities to the various events that could occur, and then update those probabilities as new information arrives. These updated probabilities are used to make better decisions.
					- ^^What can I do to control an outcome? That‚Äôs the wrong question. What can I do to influence the odds? Now that‚Äôs productive. That I can work with ‚Äì in my life and in my job.^^
	- Maxim 7 - UNCERTAINTY IS THE FRIEND OF THE STATUS QUO
		- If you have had the same credit card, bank account, gym membership, car, or toothpaste brand for many years despite the fact that ‚Äì for at least some of these choices ‚Äì you suspect there are better alternatives, you exhibit what is known as ‚Äústatus quo bias.‚Äù
		- Status quo bias challenged a central assumption of economics at the time: that humans are rational decision makers who consistently make objective choices between options to maximize their satisfaction.
		- Awareness of status quo bias and its tendency to appear in the face of uncertainty can help you make better personal and professional decisions.
		- Interestingly, one can take advantage of status quo bias to help people make better choices by setting a default option that will be good for the person making the decision. The field of behavioral economics is replete with examples of using defaults, and more generally choice architecture, to ‚Äúnudge‚Äù individuals toward good choices. For example, defaults have been used to get people to automatically enroll in retirement plans, donate organs, and purchase ‚Äúgreen‚Äù energy from sustainable sources.
	- Maxim 8 - GOOD DECISIONS SOMETIMES HAVE POOR OUTCOMES
		- ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2FFYI6sH0lrw.png?alt=media&token=10261a74-7b9d-4bf1-9bfe-4d0072cf4ac2)
		- This maxim reminds us to judge the quality of your decision by what you knew at the time you made it, not what you found out afterwards.
			- Every time I‚Äôm tempted to let the outcome of a decision determine my assessment of that decision, I try to slow my thinking down. How would I judge the process that resulted in that decision before knowing its outcome? And then, how might I update that judgment given the outcome I can now observe? That first question ‚Äì How was the process? ‚Äì disciplines my thinking in a way that is incredibly helpful in evaluating decisions made by my favorite sports teams, by my elected officials, and by me.‚Äù
		- The maxim applies to decisions as small and personal as whether to buy insurance for your iPhone and as large and important as how to steer an organization you lead during moments of crisis. In times of crisis, all potential outcomes look bad. If so, you will have to choose among options all of which will lead to bad outcomes and inevitable, but unfair, blame. The goal is to pick the option that you expect will lead to the least bad outcome.
		- If we cannot judge the quality of the decision by the quality of the outcome, how should we judge it? The key is to understand what information you had (or could have had) at the time you made the decision, and then determine whether given this information you chose a path that would maximize the expected value of your decision. The formal procedure for doing this is to draw a decision tree with nodes for choices and chance events, the probabilities associated with each chance event, and the outcomes associated with each branch of the tree. Yes, the probabilities will not be well defined, as are the probabilities of a coin flip or selecting a card. Assessing how likely you are to break your phone or like San Francisco can only be assessed subjectively. That is a major reason why decision making is difficult. But not thinking hard about probabilities, or worse not attending to them, is the path to poor decisions.
			- We illustrate the process with a simple decision tree for the decision of whether to buy insurance for your iPhone. Note that for the two alternatives you face (buy insurance or not), you have two scenarios (whether the phone breaks or not) and each scenario has different consequences depending on the choice you made. You can then calculate for each of the two main branches the expected cost (labeled EC). In this hypothetical example, the expected cost of buying insurance ($102.50) is much higher than the expected cost of not buying it ($42.50). Therefore, unless you are extremely risk averse, the rational decision would be not to buy insurance. And for these hypothetical figures, if you break your phone, it would be a bad outcome and it would cost you $850, but this does not mean the decision was a bad one.
			- Note that the expected cost is what you would expect your cost to be on average if you made this decision many times, say if you were to buy 1,000 smartphones. You might object because you are only buying one phone. Over the course of your lifetime, however, you will make thousands of decisions like this one, so thinking of what will happen on average across many decisions is helpful.
			- Simple decision tree for buying iPhone insurance
			- ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2FpNlC0xfbxl.png?alt=media&token=930e3e20-66f7-47aa-8680-cf5947054ae9)
		- Given that good decisions can sometimes result in bad outcomes, why should you go through the trouble of setting up and executing good decision-making processes? The answer is that, on average, good decisions are more likely to result in good outcomes than bad decisions. They cannot ensure good outcomes, but they increase the chances of good outcomes. If you consistently employ good decision processes, you will accumulate better outcomes over the course of many decisions. Over the course of years, this can make a huge difference in your quality of life.
		- The fact that good decisions sometimes result in bad outcomes should not lead us to assume that our bad outcomes all result from good decisions with an unlucky result. Bad outcomes often flow from bad decisions, particularly when decisions are made more on whim, and impulse outweighs thinking. The key is to judge the quality of the decision separate from the outcome, and ask yourself if you could have done better at the time you made the decision with the information you had.
		- Nevertheless, knowing that a good decision can sometimes result in a bad outcome should make us more compassionate with ourselves and with others when bad outcomes occur.
		- A corollary to this maxim is that bad decisions sometimes have good outcomes. 
		  id:: c53951b1-f8de-422f-8ac6-913387d7c205
	- Maxim 9 - SOME DECISIONS HAVE A HIGH PROBABILITY OF A BAD OUTCOME
		- Even "good" decisions doesn't necessarily lead to good outcomes all the times. For example ending child abuse would require Draconian rules and an authoritarian government that would harm citizens, so we have to make the best decisions we can to increase prevention of abuse.
	- Maxim  10 - ERRORS OF COMMISSION SHOULD BE WEIGHTED THE SAME AS ERRORS OF OMISSION
		- More generally, errors of commission generally get weighted more heavily than errors of omission, a tendency sometimes referred to as [[omission bias]].
			- An example of an error of commission is when you buy $20k worth of Amazon stocks in 1998 then a year later withdraw. In May 2021, that would have been worth $3 million.
			- An error of omission, on the other hand, is at that same time choosing not to invest $20k worth of stocks.
			- One potential reason behind omission bias is that we often do not know about the losses that arise from errors of omission. For example, if you choose not to take the job in San Francisco, you will never know how it would have turned out. You are less likely to experience regret. Whereas if you had decided to go and things had turned out poorly (an error of commission), the losses to you are much easier to see
	- Maxim 11 - DON‚ÄôT BE LIMITED BY THE OPTIONS YOU HAVE IN FRONT OF YOU
		- Decisions sometimes require you to reject the options you were given, and to look for others. Even if the outcomes of the first are satisfactory, another option if tried may give perfect results.
	- Maxim 12 - INFORMATION IS ONLY VALUABLE IF IT CAN CHANGE YOUR DECISION
		- ‚ÄúDon‚Äôt wait for information if it won‚Äôt change your decision.‚Äù or conversely, don't ask for more information if it won't change your decision. Looking at data because it is interesting may be a waste of your time.
	- Maxim 13 - LONG DIVISION IS THE MOST IMPORTANT TOOL FOR POLICY ANALYSIS
		- This maxim makes a simple but critical point: In assessing any policy measure in any realm, you should first determine what it achieves, and what resources it requires. With these tallies, you should then use long division, to compute output per unit of input.
			- Suppose you were in charge of determining vaccination sites for a state and giving them resources. To operate a site for a day costs $50,000, and on average it delivers 1,000 vaccinations a day. Thus, the cost of operation is $50 per vaccination. This information is critical if you want to know if it is worthwhile. Would you pay $50 per vaccination? Alternatively, you can think in terms of output per unit of input, such as benefit per $1,000 spent. In this case, 20 vaccinations per $1,000 spent.
		- The real world is of course more complicated than the simple example above, but the principle of comparing benefits to costs, the basis of what economists call cost-benefit and cost-effectiveness analysis, is still very valuable in helping figure out what policies should be implemented.
		- It is critical to choose the output correctly. This requires thinking carefully about what you are trying to achieve. In the case of vaccinations, the goal is not to deliver as many vaccines as possible, but to prevent death and severe illness due to the infectious disease. Since the disease differentially affects some groups, say nursing home patients and Hispanic communities, who often have more crowded housing conditions and are often ‚Äúessential workers‚Äù who must report to job sites, you would prevent more severe or fatal cases by prioritizing vaccinations for these groups.
	- Maxim 14 - ELASTICITIES ARE A POWERFUL TOOL FOR UNDERSTANDING MANY IMPORTANT THINGS IN LIFE
		- Elasticity is one of the most important concepts in economics. In general, [[elasticity]] tells us how much we expect one quantity to change when another quantity has increased by one unit (typically 1 percent). The most commonly used elasticity is the price elasticity of demand, the original application defined by the great English economist Alfred Marshall in 1890. It tells us the percent reduction in the quantity demanded of a good when the price is increased by one percent, holding everything else constant. A price elasticity of ice cream of -2 means that when the price of ice cream increases by 1 percent, the quantity of ice cream purchased goes down by 2 percent.
		- More generally, elasticity underpins a central principle in economics, to think at the margin. Economists find [[marginal thinking]] to be of extraordinary value.[67] To illustrate, let‚Äôs tackle a simplified version of a question that many professionals have had to answer implicitly or explicitly: Do you prefer to spend time at work, or with your family or on personal projects? Economists don‚Äôt regard this as a well formulated question because the answer will likely depend on how many hours you are currently working and how many hours you are currently spending with your family or on projects. If you are working few hours and have a considerable need for money, you will likely want to spend more time working. At the other end, if you are working many hours and you rarely see your family, you would probably prefer additional family hours. In sum, to answer this question it is helpful to think about the value of your last (marginal) work hour. In addition, this marginal hour may not be adding much to your income.[68] This is an elasticity-based observation: an additional unit of work time results in a relatively small number of additional dollars earned, and an incremental dollar may not be worth much to you.
		- Accordingly, when making this decision, you want to think about whether in your current situation (working as many hours as you are now), you would like to spend an extra hour working or with family. Thinking at the margin means thinking precisely in those terms: what value do you derive from that additional (also called marginal) hour? (Incidentally, in determining what you secure at the margin, you are using our long-division maxim).#[[marginal thinking]]
		- #[[betrayal aversion]]
			- Intrigued by the findings of our initial experiments in the United States, we went out into the world to see how robust betrayal aversion was. It turns out we found it everywhere we went. Many people in China and Vietnam, in Saudi Arabia and Turkey, in Brazil and in Switzerland, also exhibited betrayal aversion, though not always to the same degree as in the United States.
			- These findings have implications for institutional design. We think of legal systems‚Äô fostering trust by compensating victims for their material losses when they are wronged. But if people are betrayal averse, arrangements that focus on compensating the victims of betrayal for the material losses experienced will not effectively foster trust. For example, in many contractual arrangements, damages are thought to compensate a person for the injury caused by their counterpart, by making the potential victim of breach equally financially well off whether the contract was performed or breached. The more betrayal-averse a person is, the less effective are institutions that decrease the risk of material losses rather than the risk of betrayal.
			- This insight led to a fruitful research program that kept Richard, various doctoral students and postdoctoral fellows, and me busy for quite some time. It also lent itself to the exploration of another of Richard‚Äôs favorite concepts, elasticity. To better capture how people responded to changes in the institutional environment, specifically the cost and the likelihood of betrayal, we introduced the notion of the ‚Äúelasticity of trust.‚Äù It measures how much more people are willing to trust given changes in either the cost or the likelihood of betrayal.
			- We took the insights from our research to our teaching on negotiation and decision making, in both degree and executive education programs. In true Kennedy School fashion, this led to a request from a government to help them think about their institutions in light of betrayal aversion.
			- Richard did not join me in the United Arab Emirates, but it was a lot of fun for a young assistant professor to work with Sheikh Mohammed, the prime minister of the United Arab Emirates and the ruler of Dubai, and his cabinet in Al Ain, an oasis close to the Omani border. I taught them about decision making, trust, and negotiation. We discussed Islamic contract law and how it compared to contract law in Switzerland, a civil law country where ‚Äúpacta sunt servanda‚Äù (agreements must be kept), and in the United States where the common law notion of ‚Äúefficient breach‚Äù describes how a party can breach a contract if it finds it more attractive to pay damages than to honor its commitments.
	- Maxim - 15 HETEROGENEITY IN THE POPULATION  EXPLAINS MANY PHENOMENA
		- Many studies have attempted to explain why health expenditures are so high in the United States. One key fact that many of these studies tried to unpack is that we don‚Äôt all spend the same amount on health care. In other words, there is heterogeneity in health care spending. Indeed, an important finding from these studies is that expenditures vary widely for individuals, tending to rise with age, and also across individuals in a cohort; that is, some people spend much more than others over a lifetime.
		- Understanding this heterogeneity is key to the design of sensible health policies. For example, a policy that treats all individuals in the same way (for example, by increasing insurance premiums to try to discourage people from accessing unnecessary medical care) is unlikely to reduce overall health care expenditures. On the other hand, a policy that focuses on chronic disease ‚Äì about half of the U.S. population has one, and 86 percent of health care costs are attributable to chronic disease ‚Äì would encourage interventions that could reduce the percent of people with chronic diseases or improve the cost-effectiveness of spending devoted to people with chronic diseases.[71] This is a more promising approach. In the 1950s, when acute diseases were more common than chronic diseases, this approach would not have been as effective.
		- > He said that one of the principles he learned from Richard was the idea that ‚Äúaverage behavior‚Äù was rarely the norm in large groups. To understand group behaviors, the key was to identify the right relatively homogeneous segments of people who behaved similarly with regard to the phenomenon you were studying. After doing this, you could productively analyze the behaviors of each segment separately. Once that was done, you could reassemble the population to understand its aggregate behavior
		- Recognizing heterogeneity in the population can also help design policies for different segments of the population. For example, according to the Centers for Disease Control, more than 90 percent of COVID deaths in the United States have occurred among those 55 years or older, and fewer than 1 percent were younger than 25 years old.[74] This suggests that nursing homes are in a dramatically different risk category than are schools.
		-
	- Maxim 16 - CAPITALIZE ON COMPLEMENTARITIES
		- Imagine you are running a summer tennis camp. Assume that your only important inputs are the instructors and the courts. If you start off with a single tennis court, the value of the first instructor is high, and the value of a second instructor is still positive (since you can have two instructors in a single court), but lower. A third instructor is less valuable still. Now imagine that you had two tennis courts available instead of one. All of a sudden, the value of having a second instructor has gone up: the second instructor can now go to the second court and more children can sign up for your camp.
		- In this situation, increasing the quantity of one input (in this case tennis courts) makes an increase in the quantity of the other input (in this case tennis instructors) more valuable. Another way to see this is that after some point hiring more instructors won‚Äôt do you much good unless you have additional tennis courts. So the value of additional instructors will be higher the more tennis courts you have.
		- The example above illustrates the value of capitalizing on complementarities. Courts and instructors are complements because the value of one depends on the availability of the other. The world is full of situations like this.
		- Engage with people from different fields, interests, mindsets, countries, and ages.
			- One key application of this maxim arises when we choose a collaborator, for example in an intellectual project or in business. As Richard frequently argues, we often choose people whose skills are similar to our own. The result is that the gains from collaboration are much smaller than if we were to choose people who would bring different capabilities to the undertaking. If two engineers are planning the construction of a bridge, adding a third engineer to the team won‚Äôt help as much as adding an architect or a project manager.
			- ‚ÄúWhen you are an economic theorist, you gain more by collaborating with an empiricist than with another theorist. Similarly, if you are good at ideas and bad at follow up, you should collaborate with someone who is good at follow-up.‚Äù
		- ^^Improving collaborations^^ #[[Collaboration]] #((f26f19c8-b86c-44e9-92f9-42fdd138916f))
			- I deeply admire Richard‚Äôs ability to model successful collaboration. He identifies areas of interest where he is less knowledgeable and sees them as an opportunity to produce great value by working with experts who complement his own skills.
			- So while positive cross-partial derivatives are of course an important analytical tool, they also serve as a personal reminder to adopt a humbler mindset and work with others to have an impact.
			- Whenever I have a new idea, rather than stew on it endlessly to unlikely ‚Äúperfection" as I used to, I now solicit feedback much sooner because of this maxim. The refrain ‚Äúpositive cross-partials" in my head reminds me to put aside my own ego and to seek out perspectives to more quickly converge on a better idea.
	- Maxim 17 - STRIVE HARD NOT TO BE ENVIOUS ‚Äì SEE YOUR  FRIEND‚ÄôS SUCCESS AS YOUR GAIN
		- Social comparison was not only fruitless, but also deeply damaging. ‚ÄúIf we are constantly measuring our self-worth relative to the performance of those around us, we will always feel we fall short. I remember at some point I was discussing an aspect of my dissertation with Richard in his office, and I made a comment about how a fellow PhD student had recently made an important breakthrough in his work, but I was a bit stuck on something. This contrast had me frustrated and it showed. Richard looked at me and said something to the effect of ‚Äòyour friend‚Äôs success is only a good thing, and yours is coming. So buy him a beer.‚Äô‚Äù
		- ‚ÄúFrom that day on I stopped comparing myself to my peers and started to actively take joy in the success of others. Not only has this made me a happier person in my professional life, but also in my personal interactions. Indeed, I have found that rejecting envy helps you appreciate others more, and helps build lasting friendships and relationships. I hope that my friends and family know that I‚Äôm their biggest cheerleader and I always will be, thanks to Richard.‚Äù
		- Richard exemplifies this maxim. One of the themes that emerges from his collaborators is how generous he is with his time, advice, and support. He is also incredibly generous to his mentors, and at every turn recognizes their influence on him without a trace of envy for their success.[82] And it would have been easy for him to feel envy for his mentors: Ken Arrow and Tom Schelling won the Nobel Prize in Economics, and Howard Raiffa is broadly recognized as a pioneer in the fields of game theory, decision analysis, and negotiation analysis. Moreover, one of his students (Mike Spence) also won the Nobel Prize in Economics. Richard celebrates and cherishes the laurels these close friends merited and received.
	- Maxim 18 - ELIMINATE REGRET
		- A corollary of the ‚Äúavoid regret when a good decision leads to a bad outcome‚Äù is that you should not take pride in poorly made decisions that work out well. Moreover, even if a bad decision leads to a bad outcome, wallowing in regret is not productive. You want to reflect and learn from the bad decision but then move on. This is what Yinglan Tan, a former student of Richard‚Äôs and a Singapore-based venture capitalist, tries to do in his work: ‚ÄúVenture capitalists play the long game." #[[Decision Making]]
			- In the process it is inevitable that misses are made or bets don‚Äôt pan out. All the same, I have learned not to let any singular decision weigh down on me. Instead, I look at these misses as an opportunity to learn, and this is an exercise I regularly go through with my team. These moments that could have been occupied with regret are greater sources of insight than one would initially suspect, and are critical to shaping how we proceed with finding the best companies to work with moving forward.‚Äù
		- In sum, regret is a wasteful emotion regardless of whether the bad outcome is a result of a good or a bad decision. Realizing you made a mistake and taking action to correct it is good, but dwelling on the mistake does not do any good. Perhaps even worse, our desire to avoid regret in the future might lead us to make suboptimal decisions in the present. In the iPhone example, you might decide to buy insurance not because it makes rational sense to do so, but because you could avoid the regret you would feel were the phone to break in the future. This is no sound basis for making decisions.
	- MAXIM 19 - MAKE PLEASURE-ENHANCING DECISIONS LONG IN ADVANCE, TO INCREASE THE UTILITY OF ANTICIPATION
		- Anticipation of a future reward, such as an upcoming vacation, can be sometimes even more gratifying than the experience itself. This is the idea behind this maxim and what some people have termed anticipation utility.
		- While this maxim encourages you to think long and often about an upcoming pleasurable event, you should also avoid thinking long and often about an upcoming negative event
		- In the same way you can derive pleasure by thinking about an upcoming pleasant event, you can also enjoy remembering a pleasant event.
			- Try to maximize the pleasure (and the utility) of the decisions you have already made
		- **If you are trapped in a bad conversation, or enduring a bad meal, or cannot conveniently leave a bad play or concert or movie, Richard‚Äôs maxim teaches that you should make the best of it. And if you are in a good conversation or having a good meal or enjoying a good concert, then the same maxim says to tell yourself and your companions how good it is, all in order to increase the pleasure to be derived from the same experience.**
		- Finally, once you have made a decision, one habit that will increase your well-being is to collect information favorable to your decision (after you have made it), and to muse on the positives. So for example, if you have decided to attend a certain college, try to discover all the great things the college has to offer (such as the faculty doing work in areas you are interested in, the sense of community the school is able to foster, etc.) and give less attention to any shortcomings of the school for you (such as unexciting cafeteria food, expensive housing etc.).
	- ^^If you focus on people‚Äôs shortcomings, you‚Äôll always be disappointed ^^((895211b8-916c-415d-9045-e5a52d8b7030))
	- There are some things you just don‚Äôt want to know
- [[roam/comments]]
	- [[October 9th, 2021]]
		- [[philipr@posteo.net]
			- ((46dc3b57-d326-449d-a9c3-70d183edcf3a))
				- In designing solutions to problems or mitigation processes, don't necessarily specifically target the same exact problem, but rather consider expanding the scope of the solution. The same exact scenario is unlikely to happen, rather a similar but different enough event will occur. Make sure that the solution we design to address the initial event can also work for future similar but different enough events.
		- [[philipr@posteo.net]]
			- ((c53951b1-f8de-422f-8ac6-913387d7c205))
				- Consider luck factoring into the outcome. Outcomes should not be the judge of good decision-making, because we may misjudge bad decision-making as good.
	- [[September 16th, 2021]]
		- [[philipr@posteo.net]]
			- ((103e4354-69cd-4e33-b8b6-5d2348d85cdd))
				- When trying to solve a problem with a range of possibilities to solve, pick the extreme scenario to solve to get a clearer picture of the answer. 
				  id:: 43a1c514-b08b-4443-9044-05955c97e72c
title:: The Right It (highlights)
author:: [[Alberto Savoia]]
full-title:: "The Right It"
media:: #books

- Highlights first synced by [[Readwise]] [[2023-05-07]]
	- When new products are brought to market, failure is the rule, not the exception. Failure is so consistent, persistent, and ubiquitous that it will serve us well to treat it as a law and give it the respect it deserves.[*](https://readwise.io/reader/document_raw_content/31141700#rch1f1) The Law of Market Failure is this:
	  
	  **Most new products will fail in the market,**
	  
	  **even if competently executed.** ([View Highlight](https://read.readwise.io/read/01gzpty21tscf3m7sewvahq1gv))
	- For our purposes, *market failure* means any actual market result from an investment in a new product that is *less than or the opposite of the expected result* ([View Highlight](https://read.readwise.io/read/01gzptynrvbgj07m854nyg9zas))
	- In the broader consumer-products market, some of the best data on new-product failure comes from the venerable firm Nielsen Research. For decades, Nielsen has been tracking tens of thousands of new product launches. Every year it produces a report on how those products have fared in the market. The results are remarkably consistent: approximately 80% of new products fall short of their original expectations and are categorized as “failed,” “disappointing,” or “canceled”—year after year, with no exceptions. ([View Highlight](https://read.readwise.io/read/01gzpv6rqhf3w217edmm6taamz))
	- If you research or talk to people like authors or publishers, mobile app developers, venture capitalists, and restaurateurs, you will hear the same story and get roughly the same 80% number over and over. So if you are looking for a number to replace “most” in the Law of Market Failure, anything in the range of 70% to 90% will do. I suggest you err on the side of caution and begin by assuming a 90% chance of failure for any new product idea. ([View Highlight](https://read.readwise.io/read/01gzpv7b1ac5rh597q1q7qrx5z))
	- Most projects failed for three reasons:
	  
	  **F**ailure due to **L**aunch, **O**perations, or **P**remise
	  
	  Which gives us the appropriate (and easy to remember) acronym FLOP. ([View Highlight](https://read.readwise.io/read/01gzpx35jv83rbemns4qz1dm2f))
	- **Failure due to Launch** happens when the sales, marketing, or distribution efforts accompanying your new product fail to reach the intended market with the necessary visibility or availability ([View Highlight](https://read.readwise.io/read/01gzpx3xkwhcwh1dmkevq83vbn))
	- **Failure due to Operations** occurs when your new product’s design, functionality, or reliability fails to meet a minimum threshold of user expectations ([View Highlight](https://read.readwise.io/read/01gzpx457jqawej64w62vhehgw))
	- **Failure due to Premise** happens when people are simply not interested in your idea. They know about it, they understand it, and they believe that it does what it promises reliably and efficiently. They can also easily find it, try it, or buy it, but they just don’t care. ([View Highlight](https://read.readwise.io/read/01gzpx4p6mh5vvczwyzqdevqtz))
	- A small percentage of products fail in the market because they are poorly launched or built; the majority fail because they are the wrong product idea to start with ([View Highlight](https://read.readwise.io/read/01gzpx6e3g1df0q7v6xxa8cep9))
	- In business, there are no good ideas or bad ideas; there are only ideas that succeed in the market and ideas that fail in the market. As we have seen, most ideas will fail—even if competently executed. The minority of ideas that become a market success have one thing in common: they are *The Right It*. In other words, take an idea that is The Right It, add competent execution, and the idea will succeed in the market ([View Highlight](https://read.readwise.io/read/01gzpxb84hgsqkgdcqbfjk5y9x))
	- Even if Thoughtland-based market research could produce more dependable results—and that’s a gargantuan *if*—it still would not be my first choice, because there are, as you shall see, faster, cheaper, and far better ways to get the data we need. You can use the heel of an expensive Italian shoe to drive in a nail, but why abuse a Ferragamo when you have a proper hammer at your disposal? ([View Highlight](https://read.readwise.io/read/01gzrk7p98cg3nsypkzkp23n7j))
		- **Note**: Thought land is referencing sit down marketing based research groups and surveys. Once where participants are asked questions about their products. The author thinks this type of work should be validated by actual
		   Real world data in parallel
	- well-planned and -executed market research of this kind can occasionally provide you with *some* interesting insights. But be very careful of how much weight you put on those insights, because these are Thoughtland-based tools and, because of that, they are subject to a variety of mental traps ([View Highlight](https://read.readwise.io/read/01gzrke2vv1m7f8gtp0fx89esa))
	- **The Lost-in-Translation Problem**
	  
	  The first problem we face in Thoughtland is one of communication. Until it’s made concrete or tangible in some form, your idea for a new product or service is just an abstraction. It’s something that you imagine or picture in your head in your own unique way. The moment you try to communicate what you see in your mind’s eye to someone else, you run into a challenging translation problem—especially if your idea is new and different from anything else they’ve seen. ([View Highlight](https://read.readwise.io/read/01gzrkexzmbv6nmgp7pmgct0e6))
		- **Note**: An example in software delivery is when we put prototype and prototypes for our users to experiment and actually use.
	- This problem stems from the fact that the way you imagine the new product and its uses may be completely different from the way other people will imagine it after you describe it to them. Their interpretation of your idea is going to be distorted by their own mental trolls: their personal beliefs, preferences, and prejudices. Not only is their understanding of the idea itself likely to be different from yours, but they will *judge* the idea within the context of their unique mental model of the world. ([View Highlight](https://read.readwise.io/read/01gzrkhj90k7x84qhkrhnh879y))
	- When I first heard about the car service Uber, for example, I was seriously skeptical about its chances for success. This is how I saw and judged the idea in my head:
	  
	  *You mean, strangers get into another stranger’s car? Not a taxi with a licensed and professional driver, but just any car with any driver? Who’s going to go for that? “Don’t get into a stranger’s car” is the first thing that my mother taught me! This is a crazy idea. It’ll never work, and I’d never use it.* ([View Highlight](https://read.readwise.io/read/01gzrkkr3n0gsk0ezyhc9anmd9))
	- Even if you manage to successfully communicate your idea without major distortions caused by the translation troll, you will run into another serious issue. People are notoriously bad at predicting whether they would actually want or like something they have not yet experienced—as well as how or how often they would actually use it. ([View Highlight](https://read.readwise.io/read/01gzrkk8wr84848x0kzjky9ap4))
	- Let’s go back to Uber for another example of the Prediction Problem. Even though I had come to terms with the whole idea of jumping in a car driven by a stranger who is neither a taxi nor a limo driver, I initially thought I’d be using the service exactly the same way I was using taxis and limos—once or twice every few weeks. Wrong prediction—way wrong. I find myself using Uber three to four times more often than I’ve ever used taxis ([View Highlight](https://read.readwise.io/read/01gzrkn1nqh7zh1v4f2kny2j0t))
	- People love to give their opinions and advice; most of us do that without much thought if we have no skin in the game—because we’ve got nothing to lose or gain either way. Going back to the ABC LadyLike beer focus-group example, one of the main problems with this type of market research is that the participants don’t have any stake in the outcome. If a focus-group participant gives enthusiastic responses to the survey questions and ABC fails with LadyLike beer, it’s no foam off her nose. I’ll have a lot more to say about skin in the game later on in the book ([View Highlight](https://read.readwise.io/read/01gzrkqe3wn09hx3bpjkrkpwf8))
		- **Note**: People have to be invested in the solution otherwise feedback from focus groups are not well thought out. The interviewees should have skin in the game.
	- In other words, not only do we fail to look for objective ways to gather information, but we also fail to look objectively at the information we do get. We pick and choose and give more weight to bits of data that confirm our beliefs and dismiss those that run against them. That’s why in the US, for example, most conservatives follow conservative news channels and most liberals follow liberal news channels. ([View Highlight](https://read.readwise.io/read/01gzrkyh1b76vnsszkdr7m7dak))
	- Confirmation bias can and does affect the way we design our experiments, interpret the results, and come to conclusions. As cognitive and mathematical psychologist Amos Tverski put it: “Once we have adopted a particular hypothesis or interpretation, we grossly exaggerate the likelihood of that hypothesis, and find it very difficult to see things any other way.”[*](https://readwise.io/reader/document_raw_content/31141700#rch2f1) ([View Highlight](https://read.readwise.io/read/01gzrm7zpsfm5tnscc5t7jsb4h))
	- Bottom line: instead of dependable, objective, and actionable data, Thoughtland coughs up fur balls of subjective, biased, misguided, and misleading opinions ([View Highlight](https://read.readwise.io/read/01gzrm8avt2qcf5zg4p22189j1))
	- What most people would consider data did not pass muster at Google. In order to get serious consideration in the decision process, the data had to satisfy a number of key criteria:
	  
	  **Freshness:** The data has to be fresh—the fresher the better. That’s because what was true a few years (or months or weeks) ago may not be true today. This is particularly important in high-tech businesses and the online world, where people’s attitudes and expectations change the most rapidly. In the late 1990s, for example, one of the performance rules of thumb for websites was that a page had to load in eight seconds or less. Data from a widely publicized study showed that if a web page took longer than eight seconds to load, at least 50% of the website visitors would lose patience and leave the site.
	  
	  These days, those eight seconds would feel like an eternity to 90% of users. We expect web pages to load instantly, and if they take more than a couple of seconds, we are gone. The “eight-second rule” became the “two-second rule,” and in a few years it will probably be the “half-second rule.” Some types of data spoil faster than a banana left in the back seat of a hot car; others remain valid longer. Unfortunately, unlike ripe bananas, aging data does not develop brown spots and go mushy to alert you, nor does it come with a helpful expiration date. So it’s up to you to be careful with the data you choose to use. If in doubt about its freshness, throw it out ([View Highlight](https://read.readwise.io/read/01gzrmqa5c3an9g6nq77922da4))
	- **Strong relevance:** The data must be directly applicable to the specific product or decision being evaluated. This may sound like an obvious criterion, but you’d be surprised how often data with weak relevance can trickle into the decision process. The fact that, say, most McDonald’s customers would not order onion rings with their burgers even if they were offered does not mean that you should not include them on the menu for *your* idea for a burger food truck. ([View Highlight](https://read.readwise.io/read/01gzrmqv4xws0dzrh5etg47ztm))
	- **Known provenance:** You should not rely on data collected from other people, in other organizations, or for other projects to make your decisions. Who knows what methods those people used to collect and filter the data? And who knows what biases, influences, and motivations may have affected them when they compiled and summarized the data? The “eight-second rule” and other similar studies mentioned before, for example, were sponsored and publicized by companies that sold products and services to accelerate website performance; so they had a vested interested in showing data that supported their business offering. Make sure you know where your data comes from and how it was collected and filtered. ([View Highlight](https://read.readwise.io/read/01gzrmr53myw9b056fgtttzm23))
	- You should not rely on Other People’s Data (OPD) to determine whether your idea is likely to succeed in the market. It’s a tempting, but lazy and dangerous shortcut. ([View Highlight](https://read.readwise.io/read/01gzrn187ryf24gbmyw5zd2xw3))
	- OPD is *any market data collected and compiled by other people, for other projects, at other times, in other places, with other methods, and for other purposes* ([View Highlight](https://read.readwise.io/read/01gzrnpw8taphc2tgjsy33eg4q))
	- OPD violates one or more of the criteria of freshness, relevance, trustworthiness, and significance that we’ve just outlined. The data derived from the experiments, actions, and decisions of other people working on ideas similar to yours can be used to *supplement* and *inform* your own actions and decisions. But it’s *not sufficient* and it should *not be a substitute* for collecting your own data ([View Highlight](https://read.readwise.io/read/01gzrnq5v3ck80npa85msr3f7d))
	- Whenever you think you have a new idea for a business, product, or service, there are five possible scenarios:
	  
	  1.  You are the first person in history to come up with that idea. There’s nothing in the world like it.
	  2.  Other people have had the same or a similar idea and
	    1.  they chose not to pursue it.
	    2.  they are actively pursuing it, but have not launched it yet.
	    3.  they pursued it, launched it, and failed.
	    4.  they pursued it, launched it, and succeeded. ([View Highlight](https://read.readwise.io/read/01gzrnqpnznrgaj2m1vem48g66))
		- **Note**: These scenarios suggest we should examine the problem space for existing data to help us make informed decisions because someone may have already thought through them.
	- You should not make a decision about your idea based solely on what other people did or did not do with an idea similar to yours. Their experience, results, and data are not necessarily applicable to your idea.
	  
	  Am I telling you to ignore any and all data from other people who have pursued ideas and markets similar to yours? Not exactly. I am not telling you to completely ignore it, because there may be something, perhaps even a lot, that you can learn from OPD. But I am telling you not to depend on it, because OPD is not sufficient. When it comes to determining the market potential of a new idea, OPD is simply not enough, and it’s no substitute for *your own data*. ([View Highlight](https://read.readwise.io/read/01gzrq7vdkx37j9a7rwqss43fd))
	- Your Own DAta (YODA) is market data collected firsthand by *your own* team to validate *your own* idea. To qualify as YODA, the data must satisfy the criteria of freshness, relevance, trustworthiness, and significance ([View Highlight](https://read.readwise.io/read/01gzrq8t3hn1w7sbk9qg5q07rh))
	- *Clarity of thought is paramount*. If your new product idea is vague, imprecise, ambiguous, or open to multiple interpretations, then you don’t have a solid foundation for going forward. Before you can put an idea to the test, you must be able to articulate it with enough clarity and precision to guide the design of meaningful and revealing tests, tests whose results you can trust. ([View Highlight](https://read.readwise.io/read/01gzrqbd1w9zyn3r0g8ww40qqc))
		- **Note**: You must have your product vision clear and complete. Our current product vision at OBI is not clear enough.
	- But what is your market? And how do you define and determine engagement? You need to be 100 percent clear about these questions. Enter the Market Engagement Hypothesis, which I will abbreviate as MEH ([View Highlight](https://read.readwise.io/read/01gzrtkqr7c8x9adxfz7cnsq1h))
	- The Market Engagement Hypothesis identifies your key belief or assumption about how the market will engage with your idea. Will they want to learn more about it, explore it, try it, adopt it, buy it? And if they adopt it, try it, or buy it, how are they going to use it and how often? Will they buy it again or recommend it to friends? In other words, the MEH articulates your vision of how the market will respond to and use your idea ([View Highlight](https://read.readwise.io/read/01gzrtm7c0pd9006jwbbdd0b33))
	- One of the most valuable habits I acquired by working at Google is to avoid vague terms and to use numbers whenever possible. If “data beats opinions,” then the best way to express that data is to *say it with numbers*. For example, instead of blurting out, “I believe that if we make the ‘Subscribe’ buttons a little wider, we’ll get a few more clicks on them,” a well-trained Google employee would transform “a little wider” and “a few more clicks” into specific quantities, turning that fuzzy opinion into a testable hypothesis:
	  
	  **Fuzzy opinion:** I believe that if we make our “Subscribe” buttons a little wider, we’ll get a few more clicks on them.
	  
	  **Testable hypothesis:** If we make our “Subscribe” buttons 20% wider, we will get at least 10% more subscribers.
	  
	  By saying it with numbers, a fuzzy belief becomes a clearly stated hypothesis that can be tested. In this case, an obvious experiment would be to split users into two groups: group A (original button size) and group B (a 20% wider button), and to compare the clicks between the two groups. ([View Highlight](https://read.readwise.io/read/01gzrwr11at89vk42pxske0xwz))
	- **Test results**: Using a sample of 1,000 page views, we conducted an A/B test. The results indicate that when we increased the width of the “Subscribe” button by 20% (from 100 to 120 pixels), we got 14% more subscribers. ([View Highlight](https://read.readwise.io/read/01gzrwrcyk34bp2fh1r8gr4exw))
	- Fuzzy thinking, along with opinions, is like catnip for the Beast of Failure—an open and irresistible invitation for trouble. Nothing removes fuzziness from your thinking like numbers; and the best part is that those numbers can be just rough estimates at first ([View Highlight](https://read.readwise.io/read/01gzrwrz9qsjk4qwna602zw96f))
	- **XYZ Hypothesis**
	  
	  The Market Engagement Hypothesis is a critical first step and an essential tool. But, like a pair of scissors or a knife, if our tool is not sharp enough, it won’t be very useful. The way we sharpen a Market Engagement Hypothesis is by rewriting it using another tool: the XYZ Hypothesis ([View Highlight](https://read.readwise.io/read/01gzrx3wcvvafa2gczxc070ydn))
	- **At least X% of Y will Z.**
	  
	  Then I explained: “X% is a specific percentage of your target market. Y is a clear description of your target market. Z is how you expect the market will engage with your idea. As you may recall from your high-school algebra, X, Y, and Z are the letters we use to represent unknown variables. And at this point that’s exactly where your idea stands—you are dealing with many unknown variables. But you can begin by making educated guesses about those unknown variables, running some simple experiments to test your initial hypothesis, and making adjustments as necessary.” ([View Highlight](https://read.readwise.io/read/01gzrx2yxk88s6pzckfpyk431r))
	- At least *10% of people who live in cities with an AQI level greater than 100 will buy a $120 portable pollution sensor* (where AQI stands for Air Quality Index, an objective measure of air pollution) ([View Highlight](https://read.readwise.io/read/01gzrxyf1scr14sdbzkdbttw5v))
	- X, Y, and Z are also used to describe, measure, and graph things in three-dimensional space. In our case, the unknown three-dimensional XYZ space we are exploring and want to map and understand consists of:
	  
	  **X:** How *big* a slice, what percent, of our target market can we capture?
	  
	  **Y:** What *is* our target market?
	  
	  **Z:** *How* and exactly *to what extent* will the target market engage with our product? ([View Highlight](https://read.readwise.io/read/01gzry1zs82z894sfx0xrjjfr4))
	- The goal of *hypozooming* is to take a specific but broad hypothesis and zoom in until you have a version of that hypothesis that is *actionable and testable right now*. It’s a way to go from XYZ to xyz, a smaller, simpler, more immediately verifiable version of your Market Engagement Hypothesis. The idea is that if XYZ is true, then xyz must also be true—but xyz is much easier to test and verify. ([View Highlight](https://read.readwise.io/read/01gzry5r6tze6zatfvt6h4vpyg))
	- In the mid-1990s, brilliant innovator and entrepreneur Jeff Hawkins had an idea for the personal digital assistant (PDA) that would eventually become the PalmPilot. But before committing to it and investing in building an expensive prototype, which would have required a full team of engineers and a lot of time and money, he wanted to validate some of his assumptions about the device. He *knew* he could build it, but would he use it? What would he use it for? And how often would he use it?
	  
	  His solution was to carve a block of wood to match the intended size of the device, whittle down a chopstick to make a stylus, and use paper sleeves to simulate various user screens and functions. He carried the block of wood in his pocket for several weeks and pretended that it was a functional device in order to get insights into how he would use it. If someone asked for a meeting, for example, he’d pull out his wooden block and tap on it to simulate checking his calendar and scheduling a meeting reminder ([View Highlight](https://read.readwise.io/read/01gzsk0ads21qb0rhg99gb0bfn))
	- Remember that the primary purpose of *prototypes* is to answer such questions as:
	  
	  •   Can we build it?
	  •   Will it work as intended?
	  •   How small/big/cheap/energy-efficient can we make it? ([View Highlight](https://read.readwise.io/read/01gzsjvggxknmzyy5zqqp43xy8))
	- The primary purpose of *pretotypes*, on the other hand, is to answer such questions as:
	  
	  •   Would I use it?
	  •   How, how often, and when would I use it?
	  •   Would other people buy it?
	  •   How much would they be willing to pay for it?
	  •   How, how often, and when would they use it? ([View Highlight](https://read.readwise.io/read/01gzsjw1z0hw50hjyt3h1wm354))
	- The answers to these questions will help us answer the most critical question of all: Should we build it? ([View Highlight](https://read.readwise.io/read/01gzsjw8cpwr4vwwadhd1feez3))
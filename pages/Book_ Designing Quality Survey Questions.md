---
title: Book: Designing Quality Survey Questions
---

- Author:: [[Sheila Robinson]]
Tags:: [[survey]]
Status:: [[üì•inbox]]
Related Notes::
Notes:
	 - "The most successful surveys are those built purposefully--designed with the knowledge of how to construct quality questions with appropriate response options. Sufficient planning is required, as are multiple rounds of review and revision, and ideally, intentional testing efforts. Successful surveys are built after reviewing relevant research, studying existing successful measures (when available), and most especially, careful consultation with those we wish to have respond to our survey."

	 - Surveys primarily use [[closed-ended questions]] with distinct sets of response options or answer choices. Though some surveys use open-ended questions, they are not the majority of question types. 

	 - What makes a survey question, a quality question.
		 - "A good question is one that yields a truthful, accurate answer" ([[Bradburn]], [[Sudman]], and [[Wansink]] 2004)

		 - Quality question are [[relevant]] and [[engaging]] because we have taken time to carefully craft to reflect respondent's ability and willingness to answer, and their unique cultures and context. 
			 - This requires knowledge of how respondents comprehend, interpret, and draw from their memories the information we seek. 

		 - A good question is one which does not itself affect the answer.

	 - What makes a good survey?
		 - A quality survey [[effectively]] [[engages]] respondents in providing accurate and useful data. 

		 - A survey is a [[conversation]], and to frame that conversation such that we are able to gather the needed information, we must thoughtfully employ a purposeful survey design process that takes into account an [[understanding]] and [[empathy]] for our potential respondents. 

		 - A survey should be [[user-oriented]], and focused equally on the respondent's experience as on our own information needs. This position will result in richer and more useful data. 

		 - [[Design thinking]] is defined as [[human-centered]] approach that values the user's needs first and setting aside the designer's ego and self-interest. 
			 - [[Empathy]] is the first phase in design thinking. It is the work you do to [[understand]] the person's way of doing things, and why, their physical and emotional needs, how they think about the world, and what is [[meaningful]] to them. 
				 - What is their interests, their values, how much do they care about the survey topic and what is their relationship to the researchers.

			 - **Steps for Survey Creation**
				 - Understand and define the design process to bring clarity and focus on the survey topic. It is our responsibility to analyze the user data collected during the empathize phase to define the challenge we are taking on. 

				 - Ideation of draft questions, taking account of what we know about the respondents, our survey purpose and information needs. 

				 - After ideation, create a prototype/draft of the survey. 

				 - Test your prototype

		 - Understand the difference between your needs vs interests for the survey question

	 - It is important for the survey designer to understand the role and extent of the cognitive and communicative processes that respondents go through when answering survey questions. 
		 - Understand the many different interpretations your word choice can be understood and the varied resulting responses 

	 - [[Construct]] is something to be measured that cannot be directly observed
		 - Examples are intelligence, health, prejudice, intent to change, interest in a topic, and awareness or understanding of a social problem. 
			 - These things cannot be directly observed in person and for which we must identify [[indicator]]s
				 - Indicators tell us the state or level of something. (ex. the bars or dots of our phones telling us signal strength)

		 - [[Z: We can never make accurate measurements of constructs, only useful ones]].
			 - We may try to measure someone's intelligence on many different domains but they never will be an accurate measure, though helpful

	 - Other methods of data collection. Make sure that surveys are the optimal way to collect the data you need, otherwise you can employ other data collection tools
		 - Interviews and focus groups

		 - observation

		 - test of knowledge

		 - performance tasks

	 - Chapter 3 - Understanding Respondents
		 - Instead of focusing on what questions you want to ask, focus on what might the respondents want to tell you? What questions might they be willing to answer that would help answer the research evaluations questions?

		 - Composing high-quality survey questions requires [[empathy]] and consideration for what it takes for respondents to answer questions, the cognitive processes involved, context or cultural factors that may influence the respondent, and the factors affecting [[willingness]] and the ability to answer. 

		 - **The four components of survey response process:**
			 - comprehension
				 - Respondents use mental processes to read and understand the questions, inferring the main idea of the question and identifying what the researchers are looking for regarding a response.
					 - [[Comprehension]] can be affected by:
						 - Do not notice, misread, or ignore instructions

						 - Encounter unfamiliar [[vocabulary]]

						 - Interpret words or phrases differently from what was intended

						 - Find a question worded in an overly complex or detailed way

			 - retrieval
				 - Recalling relevant information from long-term memory, which maybe affected by [[Ease of Recall]], [[Availability Heuristic]]
					 - This component includes processes such as adopting a retrieval strategy, generating specific retrieval cues to trigger recall, recollecting individual memories, and filling in partial memories through inference. 

					 - Survey questions and retrieval questions may be affected through:
						 - the way a survey question is worded (garbage collection vs trash pickup may resonate more or less depending on the reader)

						 - the degree to which the question provides retrieval cues and the quality of cues

						 - the passage of time since the event in question and the survey

					 - Retrieving or recalling [[memory]] is actually an act of [[reconstruction]]. People do not necessarily recall a memory directly or completely. Instead, they [[rebuild]] it through remembering key parts and filling it with [[inference]]s from general knowledge of the world an of themselves. 

			 - judgment
				 - Judgement can be divided in three categories for survey purposes:
					 - judgment for factual questions
						 - The respondent determines how accurate their retrieval is before rendering a judgment and constructing or selecting a response. They must determine whether their retrieval was complete or if it needs to be supplemented by inferences

					 - judgment about dates and duration and frequencies
						 - People have difficulty remembering exact dates and frequencies relative to mundane activities

			 - response
				 - Response requires selecting and reporting an answer to a survey question.

				 - Many things can potentially go wrong in the response process, especially if the question itself is problematic.
					 - If a word is not clear, the respondent may edit their response to best fit a survey response if (closed-ended)

			 - **Use the QUAID tool to assess readability and comprehensibility of survey questions**

			 - Adopt the same language and vocabulary of the culture and community of your survey respondents

	 - Chapter 4 - Sourcing and Crafting Questions
		 - Engage potential respondents for developing questions. 

		 - Use or adapt existing measures

		 - The anatomy and physiology of survey questions
			 - The anatomy of the survey question are the parts of that make up its structure. This includes the [[question stem]], the question or statement itself, along with any response options that may accompany the stem.
				 - A question with no response option is an open-ended question. 

			 - The physiology of a survey question is a combination of:
				 - the function of the question stem and any response (their individual purposes and how they work to form a complete survey question) 

				 - the relationships between question stem and response options (how they work together)

		 - Composing [[question stems]]
			 - Avoid the following in composing survey questions:
				 - acronyms

				 - low frequency words
					 - Use more common synonyms, use angry instead of irate

				 - vague qualification terms
					 - use exact numbers or ranges instead of frequently, seldom, many or few

				 - left embedded syntactic structures
					 - (this occurs when respondents encounter several phrases, adjectives, adverbs, and prepositions before they get to the critical part of the question stem) -- Use "The boy who hit the home run had wanted to play baseball all his life" instead of "The boy who had wanted to play baseball all of his life hit the home run."

				 - ambiguous syntactic structures 
					 - When the structure of the sentence or phrase is open to more than one interpretation

				 - Dense noun phrases
					 - Use "your primary vehicle" vs "the vehicle used everyday considered to be your primary mode of transportation"

				 - quantitative mental calculations

				 - hypothetical questions
					 - avoid questions about assumed situations as opposed to current facts

				 - Numerous logical operators (connecting words such as and, but, or and if)

				 - nominalizations 
					 - verbs or adjectives that have been changed into nouns, expansion from to expand. Use should developers continue to expand..vs should developers continue the expansion of 

				 - passive constructions

				 - bridging inferences
					 - this happens when respondents must make inferences about an introductory sentence in order to answer the question that follows. 

		 - [[Ambiguous]] wording
			 - Can be avoided by returning to the survey purpose and identifying what exactly is to be measured before composing questions. Be specific in exactly what you want to measure. 

			 - Definitions of ambiguous words can also be offered to make sure the correct [[interpretation]] is communicated

		 - Avoid asking or measuring more than one thing in a survey question. Split them apart if necessary. 

		 - Avoid leading or loaded questions. For example, "How much did you enjoy the movie," assumes the respondent enjoyed the movie in the first place.

		 - ^^[[open-ended questions]]^^
			 - open-ended questions requires more time and effort on the part of respondents. They may also answer the question minimally.
				 - Create incentives for effortful respondent answers

				 - How then can you quantify the answers if needed to measure progress or improvement

				 - Open-ended questions and close ended questions may offer differing answers by respondents
					 - For example respondents when asked about job satisfaction may answer "compensation" if offered as an answer, but may not provide that as an answer in an open-ended question unless it's also in the open-ended question. 

		 - open-ended questions may also make respondents self-conscious about their writing 

		 - Why use open-ended questions?
			 - When researchers believe there will be too wide range of potential  responses 

			 - When researchers are unsure about an appropriate set of response options for a [[closed-ended questions]]. In a pretesting phase of a survey, an open-ended question can be used to identify the most common response in order to construct a closed-ended question for the final instrument

			 - When researchers want to capture rich, detailed, and nuanced understanding of correspondent's thoughts, feelings, opinions, attitudes, or experiences. This only works if respondents are able and willing to share these with us. 

			 - When researchers want respondents to answer using their "voice" their own word choices and terminology and language that is comfortable for them. 

	 - ^^How to composed [[open-ended questions]]^^
		 - The best open-ended questions are simple and highly specific, letting respondents know exactly what we hope to learn from them.

		 - **Tell them why.** Providing introductory language that describes why the questions is being asked or tells the respondent why this information is important can encourage respondents to give longer, richer, and more detailed answers. 
			 - Example: __Please don't skip the open-ended questions; we read everyone of them are are really curious to know what you think.__

		 - **Break longer or complex questions into separate parts**

	 - ^^When to use open-ended  questions^^, usually used sparing but maybe appropriate for the following reasons
		 - more detailed, nuanced answers are useful

		 - answers in respondent's own words are needed

		 - exact numbers are needed (e.g., how many cares a respondent owns)

		 - the range of possibilities is virtually infinite (e.g., how many sexual partners a respondent has had)

		 - researchers suspect that providing response options may overly influence answers

		 - when the survey is in pretesting phase and an open-ended question is needed to determine the general range of responses it will generate in order to inform the eventual design of a closed-ended question

	 - **closed-ended questions**
		 - for closed-ended questions to be effective, response options must be both exhaustive (they must fully cover the ranged of expected responses) and mutually exclusive (they must not overlap i.e., they must not encourage or compel the respondent to select more the one). 

		 - ^^types of closed-ended questions^^
			 - All closed ended questions start with a question and include a finite set of responses

			 - **multiple choice**
				 - when only two options are present it can be called a dichotomous questions

			 - **check all that apply**
				 - these questions can be problematic in that some studies have shown that respondents do not always read and consider all categories, specially if the list of categories is long. 
					 - alternatively a check all apply question can be split into a dichotomous question

					 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2Fl0NXVitYkP.png?alt=media&token=e34f3682-befa-4dc9-a36c-f942f6c9342b)

			 - **rating scale**
				 - ^^to design a good rating scale questions, researchers must do the following items^^
					 - carefully choose wording that aligns with the question stem

					 - determine the appropriate number of response categories on the scale

					 - craft either a r (i.e., from the absence of something to the presence of sometunipolahing as in "not satisfied" to "satisfied") or bipolar (i.e., from one polar opposite to the other as in "dissatisfied" to "satisfied")

					 - include a midpoint, neutral, don't know, or not applicable category as needed (one or more of these is often needed)

					 - label the response options if needed (such as with numbers or words)

					 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2FBExZPuLnHw.png?alt=media&token=1dbaf1b9-1bd0-4371-a38a-e9a24e489943)

			 - ranking scale
				 - although ranking questions allow respondents to help us understand how they see response options to each other, these questions do not allow us to understand the strength or intensity of respondent's feelings

				 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2FTuX557mPZP.png?alt=media&token=fe256ad4-e9e4-4289-9f8a-9b917e8913d9)

				 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2FBGi6oOUIGG.png?alt=media&token=6c0ebe45-f68c-4cd8-b805-23b06a6e8712)

			 - semantic differential scale
				 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2FoaJukwFs3M.png?alt=media&token=0e0aac2d-6e87-478a-a584-8cc2f0514771)

	 - **Chapter 5 - Crafting Responses**
		 - Use a 7-9 point scale range (no more utility going above 9), but it is more important that researchers pay attention tot he scale granularity that they use when designing a questionnaire, rather than simply applying conventional wisdom." Take into account the research question, survey purpose and measurement goals to determine the appropriate scale and level of granularity for each item.

		 - use a **midpoint** when we are confident that respondents could legitimately have a neutral opinion or no opinion on the domain of interest, or when forcing respondents to one side or the other may result in measurement error 

		 - **balancing response options** regardless of whether a response scale includes an odd or even number of responses, it is recommended that response options for any given question feature balance between positive and negative responses

		 - **bipolar rating scale**s tend to feature midpoints and therefore tend to have an odd number of responses
			 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2Fvj-FXmN8uR.png?alt=media&token=cc678e64-a01e-4fc4-9cf3-4a42b79c159f)

		 - **unipolar rating scale**s has likely no midpoint because there is a natural zero point such as "not effective"
			 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2Fl9W1NqONkX.png?alt=media&token=82f501ff-ab7d-4d37-a1d5-c39aae83e0d4)

		 - if unsure if to include a "**don't know**" option, a filtering question can be employed to allow the respondent to skip questions
			 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2F19t3Gfsuq8.png?alt=media&token=db1b851c-13b6-4ce8-a581-77d7c9cdcb85)

		 - frequency scales may communicate unwanted signals to the respondents for example the definition of annoyed may change when a frequency is attached. 
			 - adding parameters around concepts in the question stem, such as describing what is meant by "shopping" or letting participants know what counts as "attending a cultural event," may lessen the impact of problematic inferences respondents may make. 

			 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2F207dBEG1Z8.png?alt=media&token=703b9170-2b74-4cd4-8d0b-a63237776d6a)

		 - Likert vs Likert Like Item
			 - Likert is perhaps the most misunderstood, misused, and even mispronounced term in survey research. Rensis Likert (pronounced ‚ÄúLick-ert,‚Äù not ‚ÄúLie-kurt‚Äù) was a mid-20th-century American social psychologist, primarily known for developing the 5-point Likert scale, a psychometric scale (i.e., a carefully crafted combination of questions devised using the science of scaling) that allows a researcher to measure respondents‚Äô attitudes about particular topics (see Figure 5.10). A Likert scale is a cluster of survey items related to each other that probes a particular construct of interest with a very specific set of consistent response options (strongly disagree, disagree, neither disagree nor agree, agree, strongly agree).

			 - ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FReligion%2FPj2L4Xn69a.png?alt=media&token=9e99997f-45ca-4bd8-b201-8ad7f7fca4ac)
